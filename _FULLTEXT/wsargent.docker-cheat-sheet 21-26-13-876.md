docker cheat sheet want to improve this cheat sheet see the contributing section table of contents why docker prerequisites installation containers images networks registry and repository dockerfile layers links volumes exposing ports best practices security tips contributing why docker with docker developers can build any app in any language using any toolchain “dockerized” apps are completely portable and can run anywhere colleagues os x and windows laptops qa servers running ubuntu in the cloud and production data center vms running red hat developers can get going quickly by starting with one of the 13 000 apps available on docker hub docker manages and tracks changes and dependencies making it easier for sysadmins to understand how the apps that developers build work and with docker hub developers can automate their build pipeline and share artifacts with collaborators through public or private repositories docker helps developers build and ship higher quality applications faster what is docker prerequisites i use oh my zsh with the docker plugin for autocompletion of docker commands ymmv linux the 3 10 x kernel is the minimum requirement for docker macos 10 8 “mountain lion” or newer is required installation linux quick and easy install script provided by docker curl ssl https get docker com sh if youre not willing to run a random shell script please see the installation instructions for your distribution if you are a complete docker newbie you should follow the series of tutorials now macos download and install docker community edition if you have homebrew cask just type brew cask install docker or download and install docker toolbox docker for mac is nice but its not quite as finished as the virtualbox install see the comparison note docker toolbox is legacy you should to use docker community edition see docker toolbox https docs docker com toolbox overview once youve installed docker community edition click the docker icon in launchpad then start up a container docker run hello world thats it you have a running docker container if you are a complete docker newbie you should probably follow the series of tutorials now containers your basic isolated docker process containers are to virtual machines as threads are to processes or you can think of them as chroots on steroids lifecycle docker create creates a container but does not start it docker rename allows the container to be renamed docker run creates and starts a container in one operation docker rm deletes a container docker update updates a containers resource limits normally if you run a container without options it will start and stop immediately if you want keep it running you can use the command docker run td container id this will use the option t that will allocate a pseudo tty session and d that will detach automatically the container run container in background and print container id if you want a transient container docker run rm will remove the container after it stops if you want to map a directory on the host to a docker container docker run v hostdir dockerdir also see volumes if you want to remove also the volumes associated with the container the deletion of the container must include the v switch like in docker rm v theres also a logging driver available for individual containers in docker 1 10 to run docker with a custom log driver i e to syslog use docker run log driver syslog another useful option is docker run name yourname docker image because when you specify the name inside the run command this will allow you to start and stop a container by calling it with the name the you specified when you created it starting and stopping docker start starts a container so it is running docker stop stops a running container docker restart stops and starts a container docker pause pauses a running container freezing it in place docker unpause will unpause a running container docker wait blocks until running container stops docker kill sends a sigkill to a running container docker attach will connect to a running container if you want to integrate a container with a host process manager start the daemon with r false then use docker start a if you want to expose container ports through the host see the exposing ports section restart policies on crashed docker instances are covered here cpu constraints you can limit cpu either using a percentage of all cpus or by using specific cores for example you can tell the cpu shares setting the setting is a bit strange 1024 means 100 of the cpu so if you want the container to take 50 of all cpu cores you should specify 512 see https goldmann pl blog 2014 09 11 resource management in docker cpu for more docker run ti c 512 agileek cpuset test you can also only use some cpu cores using cpuset cpus see https agileek github io docker 2014 08 06 docker cpuset for details and some nice videos docker run ti cpuset cpus 0 4 6 agileek cpuset test note that docker can still see all of the cpus inside the container it just isnt using all of them see https github com docker docker issues 20770 for more details memory constraints you can also set memory constraints on docker docker run it m 300m ubuntu 14 04 bin bash capabilities linux capabilities can be set by using cap add and cap drop see https docs docker com engine reference run runtime privilege and linux capabilities for details this should be used for greater security to mount a fuse based filesystem you need to combine both cap add and device docker run rm it cap add sys admin device dev fuse sshfs give access to a single device docker run it device dev ttyusb0 debian bash give access to all devices docker run it privileged v dev bus usb dev bus usb debian bash more info about privileged containers here info docker ps shows running containers docker logs gets logs from container you can use a custom log driver but logs is only available for json file and journald in 1 10 docker inspect looks at all the info on a container including ip address docker events gets events from container docker port shows public facing port of container docker top shows running processes in container docker stats shows containers resource usage statistics docker diff shows changed files in the containers fs docker ps a shows running and stopped containers docker stats all shows a running list of containers import export docker cp copies files or folders between a container and the local filesystem docker export turns container filesystem into tarball archive stream to stdout executing commands docker exec to execute a command in container to enter a running container attach a new shell process to a running container called foo use docker exec it foo bin bash images images are just templates for docker containers lifecycle docker images shows all images docker import creates an image from a tarball docker build creates image from dockerfile docker commit creates image from a container pausing it temporarily if it is running docker rmi removes an image docker load loads an image from a tar archive as stdin including images and tags as of 0 7 docker save saves an image to a tar archive stream to stdout with all parent layers tags versions as of 0 7 info docker history shows history of image docker tag tags an image to a name local or registry checking docker version it is very important that you always know the current version of docker you are currently running on at any point in time this is very helpful because you get to know what features are compatible with what you have running this is also important because you know what containers to run from the docker store when you are trying to get template containers that said let see how to know what version of docker we have running currently docker version check what version of docker you have running docker version options get the server version docker version format server version 1 8 0 dump raw json data docker version format json client version 1 8 0 apiversion 1 20 gitcommit f5bae0a goversion go1 4 2 os linux arch am cleaning up while you can use the docker rmi command to remove specific images theres a tool called docker gc that will safely clean up images that are no longer used by any containers load save image load an image from file docker load my image tar gz save an existing image docker save my image my tag gzip my image tar gz import export container import a container as an image from file cat my container tar gz docker import my image my tag export an existing container docker export my container gzip my container tar gz difference between loading a saved image and importing an exported container as an image loading an image using the load command creates a new image including its history importing a container as an image using the import command creates a new image excluding the history which results in a smaller image size compared to loading an image networks docker has a networks feature not much is known about it so this is a good place to expand the cheat sheet there is a note saying that its a good way to configure docker containers to talk to each other without using ports see working with networks for more details lifecycle docker network create docker network rm info docker network ls docker network inspect connection docker network connect docker network disconnect you can specify a specific ip address for a container create a new bridge network with your subnet and gateway for your ip block docker network create subnet 203 0 113 0 24 gateway 203 0 113 254 iptastic run a nginx container with a specific ip in that block docker run rm it net iptastic ip 203 0 113 2 nginx curl the ip from any other place assuming this is a public ip block duh curl 203 0 113 2 registry repository a repository is a hosted collection of tagged images that together create the file system for a container a registry is a host a server that stores repositories and provides an http api for managing the uploading and downloading of repositories docker com hosts its own index to a central registry which contains a large number of repositories having said that the central docker registry does not do a good job of verifying images and should be avoided if youre worried about security docker login to login to a registry docker logout to logout from a registry docker search searches registry for image docker pull pulls an image from registry to local machine docker push pushes an image to the registry from local machine run local registry you can run a local registry by using the docker distribution project and looking at the local deploy instructions also see the mailing list dockerfile the configuration file sets up a docker container when you run docker build on it vastly preferable to docker commit here are some common text editors and their syntax highlighting modules you could use to create dockerfiles if you use jedit ive put up a syntax highlighting module for dockerfile you can use sublime text 2 atom vim emacs textmate vs code also see docker meets the ide instructions dockerignore from sets the base image for subsequent instructions maintainer deprecated use label instead set the author field of the generated images run execute any commands in a new layer on top of the current image and commit the results cmd provide defaults for an executing container expose informs docker that the container listens on the specified network ports at runtime note does not actually make ports accessible env sets environment variable add copies new files directories or remote file to container invalidates caches avoid add and use copy instead copy copies new files or directories to container note that this only copies as root so you have to chown manually regardless of your user workdir setting see https github com moby moby issues 30110 entrypoint configures a container that will run as an executable volume creates a mount point for externally mounted volumes or other containers user sets the user name for following run cmd entrypoint commands workdir sets the working directory arg defines a build time variable onbuild adds a trigger instruction when the image is used as the base for another build stopsignal sets the system call signal that will be sent to the container to exit label apply key value metadata to your images containers or daemons tutorial flux7s dockerfile tutorial examples examples best practices for writing dockerfiles michael crosby has some more dockerfiles best practices take 2 building good docker images building better docker images managing container configuration with metadata how to write excellent dockerfiles layers the versioned filesystem in docker is based on layers theyre like git commits or changesets for filesystems links links are how docker containers talk to each other through tcp ip ports linking into redis and atlassian show worked examples you can also resolve links by hostname this has been deprected to some extent by user defined networks note if you want containers to only communicate with each other through links start the docker daemon with icc false to disable inter process communication if you have a container with the name container specified by docker run name container and in the dockerfile it has an exposed port expose 1337 then if we create another container called linked like so docker run d link container alias name linked user wordpress then the exposed ports and aliases of container will show up in linked with the following environment variables alias port 1337 tcp port alias port 1337 tcp addr and you can connect to it that way to delete links use docker rm link generally linking between docker services is a subset of service discovery a big problem if youre planning to use docker at scale in production please read the docker ecosystem service discovery and distributed configuration stores for more info volumes docker volumes are free floating filesystems they dont have to be connected to a particular container you should use volumes mounted from data only containers for portability lifecycle docker volume create docker volume rm info docker volume ls docker volume inspect volumes are useful in situations where you cant use links which are tcp ip only for instance if you need to have two docker instances communicate by leaving stuff on the filesystem you can mount them in several docker containers at once using docker run volumes from because volumes are isolated filesystems they are often used to store state from computations between transient containers that is you can have a stateless and transient container run from a recipe blow it away and then have a second instance of the transient container pick up from where the last one left off see advanced volumes for more details container42 is also helpful you can map macos host directories as docker volumes docker run v users wsargent myapp src src you can use remote nfs volumes if youre feeling brave you may also consider running data only containers as described here to provide some data portability be aware that you can mount files as volumes exposing ports exposing incoming ports through the host container is fiddly but doable this is done by mapping the container port to the host port only using localhost interface using p docker run p 127 0 0 1 hostport containerport name container t someimage you can tell docker that the container listens on the specified network ports at runtime by using expose expose containerport note that expose does not expose the port itself only p will do that to expose the containers port on your localhosts port iptables t nat a docker p tcp dport localhostport j dnat to destination containerip port if youre running docker in virtualbox you then need to forward the port there as well using forwarded port define a range of ports in your vagrantfile like this so you can dynamically map them vagrant configure vagrantfile api version do config 49000 49900 each do port config vm network forwarded port host port guest port end end if you forget what you mapped the port to on the host container use docker port to show it docker port container containerport best practices this is where general docker best practices and war stories go the rabbit hole of using docker in automated tests bridget kromhout has a useful blog post on running docker in production at dramafever theres also a best practices blog post from lyst building a development environment with docker discourse in a docker container security this is where security tips about docker go the docker security page goes into more detail first things first docker runs as root if you are in the docker group you effectively have root access if you expose the docker unix socket to a container you are giving the container root access to the host docker should not be your only defense you should secure and harden it for an understanding of what containers leave exposed you should read understanding and hardening linux containers by aaron grattafiori this is a complete and comprehensive guide to the issues involved with containers with a plethora of links and footnotes leading on to yet more useful content the security tips following are useful if youve already hardened containers in the past but are not a substitute for understanding security tips for greatest security you want to run docker inside a virtual machine this is straight from the docker security team lead slides notes then run with apparmor seccomp selinux grsec etc to limit the container permissions see the docker 1 10 security features for more details docker image ids are sensitive information and should not be exposed to the outside world treat them like passwords see the docker security cheat sheet by thomas sjögren some good stuff about container hardening in there check out the docker bench security script download the white papers and subscribe to the mailing lists unfortunately docker does not have a unique mailing list only dev user you should start off by using a kernel with unstable patches for grsecurity pax compiled in such as alpine linux if you are using grsecurity in production you should spring for commercial support for the stable patches same as you would do for redhat its 200 a month which is nothing to your devops budget since docker 1 11 you can easily limit the number of active processes running inside a container to prevent fork bombs this requires a linux kernel 4 3 with cgroup pids y to be in the kernel configuration docker run pids limit 64 also available since docker 1 11 is the ability to prevent processes from gaining new privileges this feature have been in the linux kernel since version 3 5 you can read more about it in this blog post docker run security opt no new privileges from the docker security cheat sheet its in pdf which makes it hard to use so copying below by container solutions turn off interprocess communication with docker d icc false iptables set the container to be read only docker run read only verify images with a hashsum docker pull debian sha256 a25306f3850e1bd44541976aa7b5fd0a29be set volumes to be read only docker run v pwd secrets secrets ro debian define and run a user in your dockerfile so you dont run as root inside the container run groupadd r user useradd r g user user user user user namespaces theres also work on user namespaces it is in 1 10 but is not enabled by default to enable user namespaces remap the userns in ubuntu 15 10 follow the blog example security videos using docker safely securing your applications using docker container security do containers actually contain linux containers future or fantasy security roadmap the docker roadmap talks about seccomp support there is an apparmor policy generator called bane and theyre working on security profiles tips sources 15 docker tips in 5 minutes codefresh everyday hacks docker prune the new data management commands have landed as of docker 1 13 docker system prune docker volume prune docker network prune docker container prune docker image prune df docker system df presents a summary of the space currently used by different docker objects heredoc docker container docker build t htop eof from alpine run apk no cache add htop eof last ids alias dl docker ps l q docker run ubuntu echo hello world docker commit dl helloworld commit with command needs dockerfile docker commit run cmd postgres too many opts dl postgres get ip address docker inspect dl grep wm1 ipaddress cut d f 4 or install jq docker inspect dl jq r 0 networksettings ipaddress or using a go template docker inspect f networksettings ipaddress container name or when building an image from dockerfile when you want to pass in a build argument docker host ip ifconfig grep e 0 9 1 3 \ 3 0 9 1 3 grep v 127 0 0 1 awk print 2 cut f2 d head n1 echo docker host ip docker host ip docker build \ build arg artifactory address docker host ip t sometag \ some directory get port mapping docker inspect f range p conf networksettings ports p index conf 0 hostport end containername find containers by regular expression for i in docker ps a grep regexp pattern cut f1 d do echo i done get environment settings docker run rm ubuntu env kill running containers docker kill docker ps q delete all containers force running or stopped containers docker rm f docker ps qa delete old containers docker ps a grep weeks ago awk print 1 xargs docker rm delete stopped containers docker rm v docker ps a q f status exited delete containers after stopping docker stop docker ps aq docker rm v docker ps aq delete dangling images docker rmi docker images q f dangling true delete all images docker rmi docker images q delete dangling volumes as of docker 1 9 docker volume rm docker volume ls q f dangling true in 1 9 0 the filter dangling false does not work it is ignored and will list all volumes show image dependencies docker images viz dot tpng o docker png slimming down docker containers cleaning apt in a run layer this should be done in the same layer as other apt commands otherwise the previous layers still persist the original information and your images will still be fat run apt commands \ apt get clean \ rm rf var lib apt lists tmp var tmp flatten an image id docker run d image name bin bash docker export id docker import – flat image name for backup id docker run d image name bin bash docker export id gzip c image tgz gzip dc image tgz docker import flat image name monitor system resource utilization for running containers to check the cpu memory and network i o usage of a single container you can use docker stats container for all containers listed by id docker stats docker ps q for all containers listed by name docker stats docker ps format names for all containers listed by image docker ps a f ancestor ubuntu remove all untagged images docker rmi docker images grep “ ” awk split 0 a print a 3 remove container by a regular expression docker ps a grep wildfly awk print 1 xargs docker rm f remove all exited containers docker rm f docker ps a grep exit awk print 1 volumes can be files be aware that you can mount files as volumes for example you can inject a configuration file like this bash copy file from container docker run rm httpd cat usr local apache2 conf httpd conf httpd conf edit file vim httpd conf start container with modified configuration docker run rm ti v pwd httpd conf usr local apache2 conf httpd conf ro p 80 80 httpd contributing heres how to contribute to this cheat sheet open readme md click readme md this link edit page make changes and commit