a minimal ubuntu base image modified for docker friendliness baseimage docker only consumes 8 3 mb ram and is much more powerful than busybox or alpine see why below baseimage docker is a special docker image that is configured for correct use within docker containers it is ubuntu plus modifications for docker friendliness administration tools that are especially useful in the context of docker mechanisms for easily running multiple processes without violating the docker philosophy you can use it as a base for your own docker images baseimage docker is available for pulling from the docker registry what are the problems with the stock ubuntu base image ubuntu is not designed to be run inside docker its init system upstart assumes that its running on either real hardware or virtualized hardware but not inside a docker container but inside a container you dont want a full system you want a minimal system configuring that minimal system for use within a container has many strange corner cases that are hard to get right if you are not intimately familiar with the unix system model this can cause a lot of strange problems baseimage docker gets everything right the contents section describes all the things that it modifies why use baseimage docker you can configure the stock ubuntu image yourself from your dockerfile so why bother using baseimage docker configuring the base system for docker friendliness is no easy task as stated before there are many corner cases by the time that youve gotten all that right youve reinvented baseimage docker using baseimage docker will save you from this effort it reduces the time needed to write a correct dockerfile you wont have to worry about the base system and you can focus on the stack and the app it reduces the time needed to run docker build allowing you to iterate your dockerfile more quickly it reduces download time during redeploys docker only needs to download the base image once during the first deploy on every subsequent deploys only the changes you make on top of the base image are downloaded related resources website github docker registry discussion forum twitter blog table of contents whats inside the image overview wait i thought docker is about running a single process in a container does baseimage docker advocate fat containers or treating containers as vms inspecting baseimage docker using baseimage docker as base image getting started adding additional daemons running scripts during container startup environment variables centrally defining your own environment variables environment variable dumps modifying environment variables security system logging upgrading the operating system inside the container container administration running a one shot command in a new container running a command in an existing running container login to the container via docker exec usage login to the container via ssh enabling ssh about ssh keys using the insecure key for one container only enabling the insecure key permanently using your own key the docker ssh tool building the image yourself removing optional services conclusion whats inside the image overview looking for a more complete base image one that is ideal for ruby python node js and meteor web apps take a look at passenger docker component why is it included remarks ubuntu 16 04 lts the base system a correct init process main article docker and the pid 1 zombie reaping problem according to the unix process model the init process pid 1 inherits all orphaned child processes and must reap them most docker containers do not have an init process that does this correctly as a result their containers become filled with zombie processes over time furthermore docker stop sends sigterm to the init process which stops all services unfortunately most init systems dont do this correctly within docker since theyre built for hardware shutdowns instead this causes processes to be hard killed with sigkill which doesnt give them a chance to correctly deinitialize things this can cause file corruption baseimage docker comes with an init process sbin my init that performs both of these tasks correctly fixes apt incompatibilities with docker see https github com dotcloud docker issues 1024 syslog ng a syslog daemon is necessary so that many services including the kernel itself can correctly log to var log syslog if no syslog daemon is running a lot of important messages are silently swallowed only listens locally all syslog messages are forwarded to docker logs why syslog ng ive had bad experience with rsyslog i regularly run into bugs with rsyslog and once in a while it takes my log host down by entering a 100 cpu loop in which it cant do anything syslog ng seems to be much more stable logrotate rotates and compresses logs on a regular basis ssh server allows you to easily login to your container to inspect or administer things ssh is disabled by default and is only one of the methods provided by baseimage docker for this purpose the other method is through docker exec ssh is also provided as an alternative because docker exec comes with several caveats password and challenge response authentication are disabled by default only key authentication is allowed cron the cron daemon must be running for cron jobs to work runit replaces ubuntus upstart used for service supervision and management much easier to use than sysv init and supports restarting daemons when they crash much easier to use and more lightweight than upstart setuser a tool for running a command as another user easier to use than su has a smaller attack vector than sudo and unlike chpst this tool sets home correctly available as sbin setuser install clean a tool for installing apt packages that automatically cleans up after itself all arguments are passed to apt get y install no install recommends and after installation the apt caches are cleared to include recommended packages add install recommends baseimage docker is very lightweight it only consumes 8 3 mb of memory wait i thought docker is about running a single process in a container the docker developers advocate the philosophy of running a single logical service per container a logical service can consist of multiple os processes baseimage docker only advocates running multiple os processes inside a single container we believe this makes sense because at the very least it would solve the pid 1 problem and the syslog blackhole problem by running multiple processes we solve very real unix os level problems with minimal overhead and without turning the container into multiple logical services splitting your logical service into multiple os processes also makes sense from a security standpoint by running processes as different users you can limit the impact of vulnerabilities baseimage docker provides tools to encourage running processes as different users e g the setuser tool do we advocate running multiple logical services in a single container not necessarily but we do not prohibit it either while the docker developers are very opinionated and have very rigid philosophies about how containers should be built baseimage docker is completely unopinionated we believe in freedom sometimes it makes sense to run multiple services in a single container and sometimes it doesnt it is up to you to decide what makes sense not the docker developers does baseimage docker advocate fat containers or treating containers as vms there are people who think that baseimage docker advocates treating containers as vms because baseimage docker advocates the use of multiple processes therefore they also think that baseimage docker does not follow the docker philosophy neither of these impressions are true the docker developers advocate running a single logical service inside a single container but we are not disputing that baseimage docker advocates running multiple os processes inside a single container and a single logical service can consist of multiple os processes it follows that baseimage docker also does not deny the docker philosophy in fact many of the modifications we introduce are explicitly in line with the docker philosophy for example using environment variables to pass parameters to containers is very much the docker way and providing a mechanism to easily work with environment variables in the presence of multiple processes that may run as different users inspecting baseimage docker to look around in the image run docker run rm t i phusion baseimage version sbin my init bash l where version is one of the baseimage docker version numbers you dont have to download anything manually the above command will automatically pull the baseimage docker image from the docker registry using baseimage docker as base image getting started the image is called phusion baseimage and is available on the docker registry use phusion baseimage as base image to make your builds reproducible make sure you lock down to a specific version not to latest see https github com phusion baseimage docker blob master changelog md for a list of version numbers from phusion baseimage version use baseimage dockers init system cmd sbin my init put your own build instructions here clean up apt when done run apt get clean rm rf var lib apt lists tmp var tmp adding additional daemons you can add additional daemons e g your own app to the image by creating runit entries you only have to write a small shell script which runs your daemon and runit will keep it up and running for you restarting it when it crashes etc the shell script must be called run must be executable and is to be placed in the directory etc service name heres an example showing you how a memcached server runit entry can be made in memcached sh make sure this file is chmod x bin sh sbin setuser memcache runs the given command as the user memcache if you omit that part the command will be run as root exec sbin setuser memcache usr bin memcached var log memcached log 2 1 in dockerfile run mkdir etc service memcached copy memcached sh etc service memcached run run chmod x etc service memcached run note that the shell script must run the daemon without letting it daemonize fork it usually daemons provide a command line flag or a config file option for that running scripts during container startup the baseimage docker init system sbin my init runs the following scripts during startup in the following order all executable scripts in etc my init d if this directory exists the scripts are run in lexicographic order the script etc rc local if this file exists all scripts must exit correctly e g with exit code 0 if any script exits with a non zero exit code the booting will fail important note if you are executing the container in interactive mode i e when you run a container with it rather than daemon mode you are sending stdout directly to the terminal i interactive t terminal if you are not calling sbin my init in your run declaration sbin my init will not be executed therefore your scripts will not be called during container startup the following example shows how you can add a startup script this script simply logs the time of boot to the file tmp boottime txt in logtime sh bin sh date tmp boottime txt in dockerfile run mkdir p etc my init d copy logtime sh etc my init d logtime sh run chmod x etc my init d logtime sh shutting down your process sbin my init handles termination of children processes at shutdown when it receives a sigterm it will pass the signal onto the child processes for correct shutdown if your process is started with a shell script make sure you exec the actual process otherwise the shell will receive the signal and not your process sbin my init will terminate processes after a 5 second timeout this can be adjusted by setting environment variables give children processes 5 minutes to timeout env kill process timeout 300 give all other processes such as those which have been forked 5 minutes to timeout env kill all processes timeout 300 environment variables if you use sbin my init as the main container command then any environment variables set with docker run env or with the env command in the dockerfile will be picked up by my init these variables will also be passed to all child processes including etc my init d startup scripts runit and runit managed services there are however a few caveats you should be aware of environment variables on unix are inherited on a per process basis this means that it is generally not possible for a child process to change the environment variables of other processes because of the aforementioned point there is no good central place for defining environment variables for all applications and services debian has the etc environment file but it only works in some situations some services change environment variables for child processes nginx is one such example it removes all environment variables unless you explicitly instruct it to retain them through the env configuration option if you host any applications on nginx e g using the passenger docker image or using phusion passenger in your own image then they will not see the environment variables that were originally passed by docker we ignore home shell user and a bunch of other environment variables on purpose because not ignoring them will break multi user containers see https github com phusion baseimage docker pull 86 a workaround for setting the home environment variable looks like this run echo root etc container environment home see https github com phusion baseimage docker issues 119 my init provides a solution for all these caveats centrally defining your own environment variables during startup before running any startup scripts my init imports environment variables from the directory etc container environment this directory contains files named after the environment variable names the file contents contain the environment variable values this directory is therefore a good place to centrally define your own environment variables which will be inherited by all startup scripts and runit services for example heres how you can define an environment variable from your dockerfile run echo apachai hopachai etc container environment my name you can verify that it works as follows docker run t i your name image sbin my init bash l running bash l echo my name apachai hopachai handling newlines if youve looked carefully youll notice that the echo command actually prints a newline why does my name not contain a newline then its because my init strips the trailing newline if you intended on the value having a newline you should add another newline like this run echo e apachai hopachai\n etc container environment my name environment variable dumps while the previously mentioned mechanism is good for centrally defining environment variables itself does not prevent services e g nginx from changing and resetting environment variables from child processes however the my init mechanism does make it easy for you to query what the original environment variables are during startup right after importing environment variables from etc container environment my init will dump all its environment variables that is all variables imported from container environment as well as all variables it picked up from docker run env to the following locations in the following formats etc container environment etc container environment sh a dump of the environment variables in bash format you can source the file directly from a bash shell script etc container environment json a dump of the environment variables in json format the multiple formats make it easy for you to query the original environment variables no matter which language your scripts apps are written in here is an example shell session showing you how the dumps look like docker run t i \ env foo bar env hello my beautiful world \ phusion baseimage version sbin my init \ bash l running bash l ls etc container environment foo hello home hostname path term container cat etc container environment hello echo my beautiful world cat etc container environment json echo term xterm container lxc hostname f45449f06950 home root path usr local sbin usr local bin usr sbin usr bin sbin bin foo bar hello my beautiful world source etc container environment sh echo hello my beautiful world modifying environment variables it is even possible to modify the environment variables in my init and therefore the environment variables in all child processes that are spawned after that point in time by altering the files in etc container environment after each time my init runs a startup script it resets its own environment variables to the state in etc container environment and re dumps the new environment variables to container environment sh and container environment json but note that modifying container environment sh and container environment json has no effect runit services cannot modify the environment like that my init only activates changes in etc container environment when running startup scripts security because environment variables can potentially contain sensitive information etc container environment and its bash and json dumps are by default owned by root and accessible only to the docker env group so that any user added this group will have these variables automatically loaded if you are sure that your environment variables dont contain sensitive data then you can also relax the permissions on that directory and those files by making them world readable run chmod 755 etc container environment run chmod 644 etc container environment sh etc container environment json system logging baseimage docker uses syslog ng to provide a syslog facility to the container syslog ng is not managed as an runit service see below syslog messages are forwarded to the console log startup shutdown sequence in order to ensure that all application log messages are captured by syslog ng syslog ng is started separately before the runit supervisor process and shutdown after runit exits this uses the startup script facility provided by this image this avoids a race condition which would exist if syslog ng were managed as an runit service where runit kills syslog ng in parallel with the containers other services causing log messages to be dropped during a graceful shutdown if syslog ng exits while logs are still being produced by other services upgrading the operating system inside the container baseimage docker images contain an ubuntu 16 04 operating system you may want to update this os from time to time for example to pull in the latest security updates openssl is a notorious example vulnerabilities are discovered in openssl on a regular basis so you should keep openssl up to date as much as you can while we release baseimage docker images with the latest os updates from time to time you do not have to rely on us you can update the os inside baseimage docker images yourself and it is recommended that you do this instead of waiting for us to upgrade the os in the image run this in your dockerfile run apt get update apt get upgrade y o dpkg options force confold container administration one of the ideas behind docker is that containers should be stateless easily restartable and behave like a black box however you may occasionally encounter situations where you want to login to a container or to run a command inside a container for development inspection and debugging purposes this section describes how you can administer the container for those purposes running a one shot command in a new container note this section describes how to run a command insider a new container to run a command inside an existing running container see running a command in an existing running container normally when you want to create a new container in order to run a single command inside it and immediately exit after the command exits you invoke docker like this docker run your image command arguments however the downside of this approach is that the init system is not started that is while invoking command important daemons such as cron and syslog are not running also orphaned child processes are not properly reaped because command is pid 1 baseimage docker provides a facility to run a single one shot command while solving all of the aforementioned problems run a single command in the following manner docker run your image sbin my init command arguments this will perform the following runs all system startup files such as etc my init d and etc rc local starts all runit services runs the specified command when the specified command exits stops all runit services for example docker run phusion baseimage version sbin my init ls running etc rc local booting runit daemon runit started as pid 80 running ls bin boot dev etc home image lib lib64 media mnt opt proc root run sbin selinux srv sys tmp usr var ls exited with exit code 0 shutting down runit daemon pid 80 killing all processes you may find that the default invocation is too noisy or perhaps you dont want to run the startup files you can customize all this by passing arguments to my init invoke docker run your image sbin my init help for more information the following example runs ls without running the startup files and with less messages while running all runit services docker run phusion baseimage version sbin my init skip startup files quiet ls bin boot dev etc home image lib lib64 media mnt opt proc root run sbin selinux srv sys tmp usr var running a command in an existing running container there are two ways to run a command inside an existing running container through the docker exec tool this is builtin docker tool available since docker 1 4 internally it uses linux kernel system calls in order to execute a command within the context of a container learn more in login to the container or running a command inside it via docker exec through ssh this approach requires running an ssh daemon inside the container and requires you to setup ssh keys learn more in login to the container or running a command inside it via ssh both way have their own pros and cons which you can learn in their respective subsections login to the container or running a command inside it via docker exec you can use the docker exec tool on the docker host os to login to any container that is based on baseimage docker you can also use it to run a command inside a running container docker exec works by using linux kernel system calls heres how it compares to using ssh to login to the container or to run a command inside it pros does not require running an ssh daemon inside the container does not require setting up ssh keys works on any container even containers not based on baseimage docker cons if the docker exec process on the host is terminated by a signal e g with the kill command or even with ctrl c then the command that is executed by docker exec is not killed and cleaned up you will either have to do that manually or you have to run docker exec with t i requires privileges on the docker host to be able to access the docker daemon note that anybody who can access the docker daemon effectively has root access not possible to allow users to login to the container without also letting them login to the docker host usage start a container docker run your image find out the id of the container that you just ran docker ps now that you have the id you can use docker exec to run arbitrary commands in the container for example to run echo hello world docker exec your container id echo hello world to open a bash session inside the container you must pass t i so that a terminal is available docker exec t i your container id bash l login to the container or running a command inside it via ssh you can use ssh to login to any container that is based on baseimage docker you can also use it to run a command inside a running container heres how it compares to using docker exec to login to the container or to run a command inside it pros does not require root privileges on the docker host allows you to let users login to the container without letting them login to the docker host however this is not enabled by default because baseimage docker does not expose the ssh server to the public internet by default cons requires setting up ssh keys however baseimage docker makes this easy for many cases through a pregenerated insecure key read on to learn more enabling ssh baseimage docker disables the ssh server by default add the following to your dockerfile to enable it run rm f etc service sshd down regenerate ssh host keys baseimage docker does not contain any so you have to do that yourself you may also comment out this instruction the init system will auto generate one during boot run etc my init d 00 regen ssh host keys sh alternatively to enable sshd only for a single instance of your container create a folder with a startup script the contents of that should be in myfolder enable ssh sh make sure this file is chmod x bin sh rm f etc service sshd down ssh keygen p t dsa f etc ssh ssh host dsa key then you can start your container with docker run d v pwd myfolder etc my init d my dockerimage this will initialize sshd on container boot you can then access it with the insecure key as below or using the methods to add a secure key further you can publish the port to your machine with p 2222 22 allowing you to ssh to 127 0 0 1 2222 instead of looking up the ip address of the container about ssh keys first you must ensure that you have the right ssh keys installed inside the container by default no keys are installed so nobody can login for convenience reasons we provide a pregenerated insecure key putty format that you can easily enable however please be aware that using this key is for convenience only it does not provide any security because this key both the public and the private side is publicly available in production environments you should use your own keys using the insecure key for one container only you can temporarily enable the insecure key for one container only this means that the insecure key is installed at container boot if you docker stop and docker start the container the insecure key will still be there but if you use docker run to start a new container then that container will not contain the insecure key start a container with enable insecure key docker run your image sbin my init enable insecure key find out the id of the container that you just ran docker ps once you have the id look for its ip address with docker inspect f networksettings ipaddress id now that you have the ip address you can use ssh to login to the container or to execute a command inside it download the insecure private key curl o insecure key fsl https github com phusion baseimage docker raw master image services sshd keys insecure key chmod 600 insecure key login to the container ssh i insecure key root ip address running a command inside the container ssh i insecure key root ip address echo hello world enabling the insecure key permanently it is also possible to enable the insecure key in the image permanently this is not generally recommended but is suitable for e g temporary development or demo environments where security does not matter edit your dockerfile to install the insecure key permanently run usr sbin enable insecure key instructions for logging into the container is the same as in section using the insecure key for one container only using your own key edit your dockerfile to install an ssh public key install an ssh of your choice copy your key pub tmp your key pub run cat tmp your key pub root ssh authorized keys rm f tmp your key pub then rebuild your image once you have that start a container based on that image docker run your image name find out the id of the container that you just ran docker ps once you have the id look for its ip address with docker inspect f networksettings ipaddress id now that you have the ip address you can use ssh to login to the container or to execute a command inside it login to the container ssh i path to your key root ip address running a command inside the container ssh i path to your key root ip address echo hello world the docker ssh tool looking up the ip of a container and running an ssh command quickly becomes tedious luckily we provide the docker ssh tool which automates this process this tool is to be run on the docker host not inside a docker container first install the tool on the docker host curl fail l o https github com phusion baseimage docker archive master tar gz \ tar xzf master tar gz \ sudo baseimage docker master install tools sh then run the tool as follows to login to a container using ssh docker ssh your container id you can lookup your container id by running docker ps by default docker ssh will open a bash session you can also tell it to run a command and then exit docker ssh your container id echo hello world building the image yourself if for whatever reason you want to build the image yourself instead of downloading it from the docker registry follow these instructions clone this repository git clone https github com phusion baseimage docker git cd baseimage docker start a virtual machine with docker in it you can use the vagrantfile that weve already provided vagrant up vagrant ssh cd vagrant build the image make build if you want to call the resulting image something else pass the name variable like this make build name joe baseimage removing optional services the default baseimage docker installs syslog ng cron and sshd services during the build process in case you dont need one or more of these services in your image you can disable its installation as shown in the following example to prevent sshd from being installed into your image set 1 to the disable ssh variable in the image buildconfig file in image buildconfig default services set 1 to the service you want to disable export disable syslog 0 export disable ssh 1 export disable cron 0 then you can proceed with make build command conclusion using baseimage docker tweet about us or follow us on twitter having problems want to participate in development please post a message at the discussion forum looking for a more complete base image one that is ideal for ruby python node js and meteor web apps take a look at passenger docker please enjoy baseimage docker a product by phusion