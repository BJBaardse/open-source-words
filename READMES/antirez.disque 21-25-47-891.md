disque an in memory distributed job queue disque is an ongoing experiment to build a distributed in memory message broker its goal is to capture the essence of the redis as a jobs queue use case which is usually implemented using blocking list operations and move it into an ad hoc self contained scalable and fault tolerant design with simple to understand properties and guarantees but still resembling redis in terms of simplicity performance and implementation as a c non blocking networked server currently 2 jan 2016 the project is in release candidate state people are encouraged to start evaluating it and report bugs and experiences warning this is beta code and may not be suitable for production usage the api is considered to be stable if not for details that may change in the next release candidates however its new code so handle with care what is a message queue hint skip this section if you are familiar with message queues you know how humans use text messages to communicate right i could write my wife please get the milk at the store and she maybe will reply ok message received ill get two bottles on my way home a message queue is the same as human text messages but for computer programs for example a web application when an user subscribes may send another process that handles sending emails please send the confirmation email to tom example net message systems like disque allow communication between processes using different queues so a process can send a message to a queue with a given name and only processes which fetch messages from this queue will return those messages moreover multiple processes can listen for messages in a given queue and multiple processes can send messages to the same queue the important part of a message queue is to be able to provide guarantees so that messages are eventually delivered even in the face of failures so even if in theory implementing a message queue is very easy to write a very robust and scalable one is harder than it may appear give me the details disque is a distributed and fault tolerant message broker so it works as a middle layer among processes that want to exchange messages producers add messages that are served to consumers since message queues are often used in order to process delayed jobs disque often uses the term job in the api and in the documentation however jobs are actually just messages in the form of strings so disque can be used for other use cases in this documentation jobs and messages are used in an interchangeable way job queues with a producer consumer model are pretty common so the devil is in the details a few details about disque are disque is a synchronously replicated job queue by default when a new job is added it is replicated to w nodes before the client gets an acknowledgement about the job being added w 1 nodes can fail and the message will still be delivered disque supports both at least once and at most once delivery semantics at least once delivery semantics is where most effort was spent in the design and implementation while at most once semantics is a trivial result of using a retry time set to 0 which means never re queue the message again and a replication factor of 1 for the message not strictly needed but it is useless to have multiple copies of a message around if it will be delivered at most one time you can have at the same time both at least once and at most once jobs in the same queues and nodes since this is a per message setting disque at least once delivery is designed to approximate single delivery when possible even during certain kinds of failures this means that while disque can only guarantee a number of deliveries equal or greater to one it will try hard to avoid multiple deliveries whenever possible disque is a distributed system where all nodes have the same role aka it is multi master producers and consumers can attach to whatever node they like and there is no need for producers and consumers of the same queue to stay connected to the same node nodes will automatically exchange messages based on load and client requests disque is available it is an eventually consistent ap system in cap terms producers and consumers can make progress as long as a single node is reachable disque supports optional asynchronous commands that are low latency for the client but provide less guarantees for example a producer can add a job to a queue with a replication factor of 3 but may want to run away before knowing if the contacted node was really able to replicate it to the specified number of nodes or not the node will replicate the message in the background in a best effort way disque automatically re queues messages that are not acknowledged as already processed by consumers after a message specific retry time there is no need for consumers to re queue a message if it was not processed disque uses explicit acknowledges in order for a consumer to signal a message as delivered or using a different terminology to signal a job as already processed disque queues only provides best effort ordering each queue sorts messages based on the job creation time which is obtained using the wall clock of the local node where the message was created plus an incremental counter for messages created in the same millisecond so messages created in the same node are normally delivered in the same order they were created this is not causal ordering since correct ordering is violated in different cases when messages are re issued because they are not acknowledged because of nodes local clock drifts and when messages are moved to other nodes for load balancing and federation in this case you end with queues having jobs originated in different nodes with different wall clocks however all this also means that normally messages are not delivered in random order and usually messages created first are delivered first note that since disque does not provide strict fifo semantics technically speaking it should not be called a message queue and it could better identified as a message broker however i believe that at this point in the it industry a message queue is often more lightly used to identify a generic broker that may or may not be able to guarantee order in all cases given that we document the semantics very clearly i grant myself the right to call disque a message queue anyway disque provides the user with fine grained control for each job using three time related parameters and one replication parameter for each job the user can control the replication factor how many nodes have a copy the delay time the min time disque will wait before putting the message in a queue making the message deliverable the retry time how much time should elapse since the last time the job was queued and without an acknowledge about the job delivery before the job is re queued for delivery the expire time how much time should elapse for the job to be deleted regardless of whether it was successfully delivered i e acknowledged or not finally disque supports optional disk persistence which is not enabled by default but that can be handy in single data center setups and during restarts other minor features are ability to block queues a few statistics about queue activity stateless iterators for queues and jobs commands to control the visibility of single jobs easy resize of the cluster adding nodes is trivial graceful removal of nodes without losing job replicas acks and retries disques implementation of at least once delivery semantics is designed in order to avoid multiple delivery during certain classes of failures it is not able to guarantee that no multiple deliveries will occur however there are many at least once workloads where duplicated deliveries are acceptable or explicitly handled but not desirable either a trivial example is sending emails to users it is not terrible if an user gets a duplicated email but is important to avoid it when possible or doing idempotent operations that are expensive all the times where it is critical for performance to avoid multiple deliveries in order to avoid multiple deliveries when possible disque uses client acks when a consumer processes a message correctly it should acknowledge this fact to disque acks are replicated to multiple nodes and are garbage collected as soon as the system believes it is unlikely that more nodes in the cluster have the job the ack refers to still active under memory pressure or under certain failure scenarios acks are eventually discarded more explicitly a job is replicated to multiple nodes but usually only queued in a single node there is a difference between having a job in memory and queueing it for delivery nodes having a copy of a message if a certain amount of time has elapsed without getting the ack for the message will re queue it nodes will run a best effort protocol to avoid re queueing the message multiple times acks are replicated and garbage collected across the cluster so that eventually processed messages are evicted this happens asap if there are no failures nor network partitions for example if a node having a copy of a job gets partitioned away during the time the job gets acknowledged by the consumer it is likely that when it returns in a reasonable amount of time that is before the retry time is reached it will be informed about the ack and will avoid to re queue the message similarly jobs can be acknowledged during a partition to just a single available node and when the partition heals the ack will be propagated to other nodes that may still have a copy of the message so an ack is just a proof of delivery that is replicated and retained for some time in order to make multiple deliveries less likely to happen in practice as already mentioned in order to control replication and retries a disque job has the following associated properties number of replicas delay retry and expire if a job has a retry time set to 0 it will get queued exactly once and in this case a replication factor greater than 1 is useless and signaled as an error to the user so it will get delivered either a single time or will never get delivered while jobs can be persisted on disk for safety queues arent so this behavior is guaranteed even when nodes restart after a crash whatever the persistence configuration is however when nodes are manually restarted by the sysadmin for example for upgrades queues are persisted correctly and reloaded at startup since the store load operation is atomic in this case and there are no race conditions possible it is not possible that a job was delivered to a client and is persisted on disk as queued at the same time fast acknowledges disque supports a faster way to acknowledge processed messages via the fastack command the normal acknowledge is very expensive from the point of view of messages exchanged between nodes this is what happens during a normal acknowledge the client sends ackjob to one node the node sends a setack message to everybody it believes to have a copy the receivers of setack reply with gotack to confirm the node finally sends deljob to all the nodes note actual garbage collection is more complex in case of failures and is explained in the state machine later the above is what happens 99 of times if a message is replicated to 3 nodes acknowledging requires 1 2 2 2 messages for the sake of retaining the ack if some nodes may not be reached when the message is acknowledged this makes the probability of multiple deliveries of this message less likely however the alternative fast ack while less reliable is much faster and invovles exchanging less messages this is how a fast acknowledge works the client sends fastack to one node the node evicts the job and sends a best effort deljob to all the nodes that may have a copy or to all the cluster if the node was not aware of the job if during a fast acknowledge a node having a copy of the message is not reachable for example because of a network partition the node will deliver the message again since it has a non acknowledged copy of the message and there is nobody able to inform it the message has been acknowledged when the partition heals if the network you are using is pretty reliable and you are very concerned with performance and multiple deliveries in the context of your applications are a non issue then fastack is probably the way to go dead letter queue many message queues implement a feature called dead letter queue it is a special queue used in order to accumulate messages that cannot be processed for some reason common causes could be the message was delivered too many times but never correctly processed the message time to live reached zero before it was processed some worker explicitly asked the system to flag the message as having issues the idea is that the administrator of the system checks usually via automatic systems if there is something in the dead letter queue in order to understand if there is some software error or other kind of error preventing messages from being processed as expected since disque is an in memory system the message time to live is an important property when it is reached we want messages to go away since the ttl should be chosen so that after such a time it is no longer meaningful to process the message in such a system to use memory and create a queue in response to an error or to messages timing out looks like a non optimal idea moreover due to the distributed nature of disque dead letters could end up spawning multiple nodes and having duplicated entries in them so disque uses a different approach each node message representation has two counters a nacks counter and an additional deliveries counter the counters are not consistent among nodes having a copy of the same message they are just best effort counters that may not increment in some node during network partitions the idea of these two counters is that one is incremented every time a worker uses the nack command to tell the queue the message was not processed correctly and should be put back on the queue asap the other is incremented for every other condition different than the nack call that requires a message to be put back on the queue again this includes messages that get lost and are enqueued again or messages that are enqueued on one side of the partition since the message was processed on the other side and so forth using the getjob command with the withcounters option or using the show command to inspect a job it is possible to retrieve these two counters together with the other job information so if a worker before processing a message sees the counters have values over some application defined limit it can notify operations people in multiple ways it may send an email set a flag in a monitoring system put the message in a special queue simulating the dead letter feature attempt to process the message and report the stack trace of the error if any basically the exact handling of the feature is up to the application using disque note that the counters dont need to be consistent in the face of failures or network partitions the idea is that eventually if a message has issues the counters will get incremented enough times to reach the limit selected by the application as a warning threshold the reason for having two distinct counters is that applications may want to handle the case of explicit negative acknowledges via nack differently than multiple deliveries because of timeouts or messages getting lost disque and disk persistence disque can be operated in memory only using synchronous replication as a durability guarantee or can be operated using the append only file where jobs creations and evictions are logged on disk with configurable fsync policies and reloaded at restart aof is recommended especially if you run in a single availability zone where a mass reboot of all your nodes is possible normally disque only reloads job data in memory without populating queues since unacknowledged jobs are requeued eventually moreover reloading queue data is not safe in the case of at most once jobs having the retry value set to 0 however a special option is provided in order to reload the full state from the aof this is used together with an option that allows shutting down the server just after the aof is generated from scratch in order to make it safe even to reload jobs with retry set to 0 since the aof is generated while the server no longer accepts commands from clients so no race condition is possible even when running memory only disque is able to dump its memory on disk and reload from disk on controlled restarts for example in order to upgrade the software this is how to perform a controlled restart that works whether aof is enabled or not config set aof enqueue jobs once yes config rewrite shutdown rewrite aof at this point we have a freshly generated aof on disk and the server is configured in order to load the full state only at the next restart aof enqueue jobs once is automatically turned off after the restart we can just restart the server with the new software or in a new server and it will restart with the full state note that aof enqueue jobs once implies loading the aof even if aof support is switched off so there is no need to enable aof just for the upgrade of an in memory only server job ids disque jobs are uniquely identified by an id like the following d dcb833cf 8yl1nt17e9 wsa 09nqxscqi 05a1 job ids are composed of exactly 40 characters and start with the prefix d we can split an id into multiple parts d dcb833cf 8yl1nt17e9 wsa 09nqxscqi 05a1 d is the prefix dcb833cf is the first 8 bytes of the node id where the message was generated 8yl1nt17e9 wsa 09nqxscqi is the 144 bit id pseudo random part encoded in base64 05a1 is the job ttl in minutes because of it message ids can be expired safely even without having the job representation ids are returned by addjob when a job is successfully created are part of the getjob output and are used in order to acknowledge that a job was correctly processed by a worker part of the node id is included in the message so that a worker processing messages for a given queue can easily guess what are the nodes where jobs are created and move directly to these nodes to increase efficiency instead of listening for messages in a node that will require to fetch messages from other nodes only 32 bits of the original node id is included in the message however in a cluster with 100 disque nodes the probability of two nodes having identical 32 bit id prefixes is given by the birthday paradox p 100 2 32 000001164 in case of collisions the workers may just make a non efficient choice collisions in the 144 bits random part are believed to be impossible since it is computed as follows 144 bit id high 144 bits of sha1 seed counter where seed is a seed generated via dev urandom at startup counter is a 64 bit counter incremented at every id generation so there are 22300745198530623141535718272648361505980416 possible ids selected in a uniform way while the probability of a collision is non zero mathematically in practice each id can be regarded as unique the encoded ttl in minutes has a special property it is always even for at most once jobs job retry value set to 0 and is always odd otherwise this changes the encoded ttl precision to 2 minutes but allows to tell if a job id is about a job with deliveries guarantees or not note that this fact does not mean that disque jobs ttls have a precision of two minutes the ttl field is only used to expire job ids of jobs a given node does not actually have a copy search dummy ack in this documentation for more information setup to play with disque please do the following compile disque if you can compile redis you can compile disque its the usual no external deps thing just type make binaries disque and disque server will end up in the src directory run a few disque nodes on different ports create different disque conf files following the example disque conf in the source distribution after you have them running you need to join the cluster just select a random node among the nodes you are running and send the command cluster meet ip port for every other node in the cluster please note that you need to open two tcp ports on each node the base port of the disque instance for example 7711 plus the cluster bus port which is always at a fixed offset obtained summing 10000 to the base port so in the above example you need to open both 7711 and 17711 disque uses the base port to communicate with clients and the cluster bus port to communicate with other disque processes to run a node just call disque server for example if you are running three disque servers in port 7711 7712 7713 in order to join the cluster you should use the disque command line tool and run the following commands disque p 7711 cluster meet 127 0 0 1 7712 disque p 7711 cluster meet 127 0 0 1 7713 your cluster should now be ready you can try to add a job and fetch it back in order to test if everything is working disque p 7711 127 0 0 1 7711 addjob queue body 0 d dcb833cf 8yl1nt17e9 wsa 09nqxscqi 05a1 127 0 0 1 7711 getjob from queue 1 1 queue 2 d dcb833cf 8yl1nt17e9 wsa 09nqxscqi 05a1 3 body remember that you can add and get jobs from different nodes as disque is multi master also remember that you need to acknowledge jobs otherwise theyll never go away from the server memory unless the time to live is reached main api the disque api is composed of a small set of commands since the system solves a single very specific problem the three main commands are addjob queue name job ms timeout replicate count delay sec retry sec ttl sec maxlen count async adds a job to the specified queue arguments are as follows queue name is the name of the queue any string basically you dont need to create queues if a queue does not exist it gets created automatically if one has no more jobs it gets removed job is a string representing the job disque is job meaning agnostic for it a job is just a message to deliver job max size is 4gb ms timeout is the command timeout in milliseconds if no async is specified and the replication level specified is not reached in the specified number of milliseconds the command returns with an error and the node does a best effort cleanup that is it will try to delete copies of the job across the cluster however the job may still be delivered later note that the actual timeout resolution is 1 10 of second or worse with the default server hz replicate count is the number of nodes the job should be replicated to delay sec is the number of seconds that should elapse before the job is queued by any server by default there is no delay retry sec period after which if no ack is received the job is put into the queue again for delivery if retry is 0 the job has at most once delivery semantics the default retry time is 5 minutes with the exception of jobs having a ttl so small that 10 of ttl is less than 5 minutes in this case the default retry is set to ttl 10 with a minimum value of 1 second ttl sec is the max job life in seconds after this time the job is deleted even if it was not successfully delivered if not specified the default ttl is one day maxlen count specifies that if there are already count messages queued for the specified queue name the message is refused and an error reported to the client async asks the server to let the command return asap and replicate the job to other nodes in the background the job gets queued asap while normally the job is put into the queue only when the client gets a positive reply the command returns the job id of the added job assuming async is specified or if the job was replicated correctly to the specified number of nodes otherwise an error is returned getjob nohang timeout ms timeout count count withcounters from queue1 queue2 queuen return jobs available in one of the specified queues or return null if the timeout is reached a single job per call is returned unless a count greater than 1 is specified jobs are returned as a three element array containing the queue name the job id and the job body itself if jobs are available in multiple queues queues are processed left to right if there are no jobs for the specified queues the command blocks and messages are exchanged with other nodes in order to move messages about these queues to this node so that the client can be served options nohang ask the command to not block even if there are no jobs in all the specified queues this way the caller can just check if there are available jobs without blocking at all withcounters return the best effort count of nacks negative acknowledges received by this job and the number of additional deliveries performed for this job see the dead letters section for more information ackjob jobid1 jobid2 jobidn acknowledges the execution of one or more jobs via job ids the node receiving the ack will replicate it to multiple nodes and will try to garbage collect both the job and the acks from the cluster so that memory can be freed a node receiving an ackjob command about a job id it does not know will create a special empty job with the state set to acknowledged called a dummy ack the dummy ack is used in order to retain the acknolwedge during a netsplit if the ackjob is sent to a node that does not have a copy of the job when the partition heals job garbage collection will be attempted however since the job id encodes information about the job being an at most once or an at least once job the dummy ack is only created for at least once jobs fastack jobid1 jobid2 jobidn performs a best effort cluster wide deletion of the specified job ids when the network is well connected and there are no node failures this is equivalent to ackjob but much faster due to less messages being exchanged however during failures it is more likely that fast acknowledges will result in multiple deliveries of the same messages working jobid claims to be still working with the specified job and asks disque to postpone the next time it will deliver the job again the next delivery is postponed for the job retry time however the command works in a best effort way since there is no way to guarantee during failures that another node in a different network partition wont perform a delivery of the same job another limitation of the working command is that it cannot be sent to nodes not knowing about this particular job in such a case the command replies with a nojob error similarly if the job is already acknowledged an error is returned note that the working command is refused by disque nodes if 50 of the job time to live has already elapsed this limitation makes disque safer since usually the retry time is much smaller than the time to live of a job so it cant happen that a set of broken workers monopolize a job with working and never process it after 50 of the ttl has elapsed the job will be delivered to other workers anyway note that working returns the number of seconds you likely postponed the message visibility for other workers the command basically returns the retry time of the job so the worker should make sure to send the next working command before this time elapses moreover a worker that may want to use this interface may fetch the retry value with the show command when starting to process a message or may simply send a working command asap like in the following example in pseudo code retry working jobid reset timer while work with the job still not finished if timer reached 80 of the retry time working jobid reset timer end end nack job id job id the nack command tells disque to put the job back in the queue asap it is very similar to enqueue but it increments the job nacks counter instead of the additional deliveries counter the command should be used when the worker was not able to process a message and wants the message to be put back into the queue in order to be processed again other commands info generic server information stats hello returns hello format version this node id all the nodes ids ip addresses ports and priority lower is better means a node is more available clients should use this as a handshake command when connecting with a disque node qlen queue name return the length of the queue qstat queue name show information about a queue as an array of key value pairs below is an example of the output however implementations should not rely on the order of the fields nor on the existence of the fields listed they may be unlikely removed or more can be likely added in the future if a queue does not exist null is returned note that queues are automatically evicted after some time if empty and without clients blocked waiting for jobs even if there are active jobs for the queue so the non existence of a queue does not mean there are not jobs in the node or in the whole cluster about this queue the queue will be immediately created again when needed to serve requests example output qstat foo 1 name 2 foo 3 len 4 integer 56520 5 age 6 integer 601 7 idle 8 integer 3 9 blocked 10 integer 50 11 import from 12 1 dcb833cf8f42fbb7924d92335ff6d67d3cea6e3d 2 4377bdf656040a18d8caf4d9f409746f1f9e6396 13 import rate 14 integer 19243 15 jobs in 16 integer 3462847 17 jobs out 18 integer 3389522 19 pause 20 none most fields should be obvious the import from field shows a list of node ids this node is importing jobs from for this queue in order to serve clients requests the import rate is the instantaneous amount of jos sec we import in order to handle our outgoing traffic getjob commands blocked is the number of clients blocked on this queue right now age and idle are reported in seconds the jobs in and out counters are incremented every time a job is enqueued or dequeued for any reason qpeek queue name count return without consuming from the queue count jobs if count is positive the specified number of jobs are returned from the oldest to the newest in the same best effort fifo order as getjob if count is negative the commands changes behavior and shows the count newest jobs from the newest from the oldest enqueue job id job id queue jobs if not already queued dequeue job id job id remove the job from the queue deljob job id job id completely delete a job from a node note that this is similar to fastack but limited to a single node since no deljob cluster bus message is sent to other nodes show job id describe the job qscan count count busyloop minlen len maxlen len importrate rate the command provides an interface to iterate all the existing queues in the local node providing a cursor in the form of an integer that is passed to the next command invocation during the first call the cursor must be 0 in the next calls the cursor returned in the previous call is used in the next the iterator guarantees to return all the elements but may return duplicated elements options count count a hint about how much work to do per iteration busyloop block and return all the elements in a busy loop minlen count dont return elements with less than count jobs queued maxlen count dont return elements with more than count jobs queued importrate rate only return elements with a job import rate from other nodes rate the cursor argument can be in any place the first non matching option that has valid cursor form of an unsigned number will be sensed as a valid cursor jscan cursor count count busyloop queue queue state state1 state state2 state staten reply all id the command provides an interface to iterate all the existing jobs in the local node providing a cursor in the form of an integer that is passed to the next command invocation during the first call the cursor must be 0 in the next calls the cursor returned in the previous call is used in the next the iterator guarantees to return all the elements but may return duplicated elements options count count a hint about how much work to do per iteration busyloop block and return all the elements in a busy loop queue queue return only jobs in the specified queue state state return jobs in the specified state can be used multiple times for a logical or reply type job reply type type can be all or id default is to report just the job id if all is specified the full job state is returned like for the show command the cursor argument can be in any place the first non matching option that has valid cursor form of an unsigned number will be sensed as a valid cursor pause queue name option1 option2 optionn control the paused state of a queue possibly broadcasting the command to other nodes in the cluster disque queues can be paused in both directions input and output or both pausing a queue makes it unavailable for input or output operations specifically a queue paused in input will have changed behavior in the following ways addjob returns a paused error for queues paused in input the node where the queue is paused no longer accepts to replicate jobs for this queue when requested by other nodes since addjob by default uses synchronous replication it means that if the queue is paused in enough nodes adding jobs with a specified level of replication may fail in general the node where the queue is paused will not create new jobs in the local node about this queue the job no longer accepts enqueue messages from other nodes those messages are usually used by nodes in out of memory conditions that replicate jobs externally not holding a copy in order to put the job in the queue of some random node among the nodes having a copy of a job active jobs that reach their retry time are not put back into the queue instead their retry timer is updated and the node will try again later basically a queue paused in input never creates new jobs for this queue and never puts active jobs jobs for which the node has a copy but are not currently queued back in the queue for all the time the queue is paused a queue paused in output instead will behave in the following way getjob will block even if there are jobs available in the specified queue instead of serving the jobs but getjob will unblock if the queue output pause is cleared later the node will not provide jobs to other nodes in the context of node federation for paused queues so a queue paused in output will stop acting as a source of messages for both local and non local clients the paused state can be set for each queue using the pause command followed by options to specify how to change the paused state possible options are in pause the queue in input out pause the queue in output all pause the queue in input and output same as specifying both the in and out options none clear the paused state in input and output state just report the current queue state bcast send a pause command to all the reachable nodes of the cluster to set the same queue in the other nodes to the same state the command always returns the state of the queue after the execution of the specified options so the return value is one of in out all none queues paused in input or output are never evicted to reclaim memory even if they are empty and inactive for a long time since otherwise the paused state would be forgotten for example in order to block output for the queue myqueue in all the currently reachable nodes the following command should be send to a single node pause myqueue out bcast to specify all is the same as to specify both in and out so the two following forms are equivalent pause myqueue in out pause myqueue all to just get the current state use pause myqueue state none special handling of messages with retry set to 0 in order to provide a coherent api messages with at most once delivery semantics are still retained after being delivered a first time and should be acknowledged like any other message of course the acknowledge is not mandatory since the message may be lost and there is no way for the receiver to get the same message again since the message is associated with a retry value of 0 in order to avoid non acknowledged messages with retry set to 0 from leaking into disque and eating all the memory when the disque server memory is full and starts to evict it does not just evict acknowledged messages but also can evict non acknowledged messages having at the same time the following two properties their retry is set to 0 the job was already delivered in theory acknowledging a job that will never be retried is a waste of time and resources however this design has hidden advantages the api is exactly the same for all the kinds of jobs after the job is delivered it is still possible to examine it observability is a very good property of messaging systems however not acknowledging the job does not result in big issues since they are evicted eventually during memory pressure adding and removing nodes at runtime adding nodes is trivial and just consists in starting a new node and sending it a cluster meet command assuming the node you just started is located at address 192 168 1 10 port 7714 and a random you can use any node of the existing cluster is located at 192 168 1 9 port 7711 all you need to do is disque h 192 168 1 10 p 7714 cluster meet 192 168 1 9 7711 note that you can invert the source and destination arguments and the new node will still join the cluster it does not matter if its the old node to meet the new one or the other way around in order to remove a node it is possible to use the crude way of just shutting it down and then use cluster forget old node id in all the other nodes in order to remove references to it from the configuration of the other nodes however this means that for example messages that had a replication factor of 3 and one of the replicas was the node you are shutting down suddenly are left with just 2 replicas even if no actual failure happened moreover if the node you are removing had messages in queue youll need to wait the retry time before the messages will be queued again for all these reasons disque has a better way to remove nodes which is described in the next section gracefully removal of nodes in order to empty a node of its content before removing it it is possible to use a feature that puts a node in leaving state to enable this feature just contact the node to remove and use the following command cluster leaving yes the node will start advertising itself as leaving so in a matter of seconds all the cluster will know if there are partitions when the partition heals all the nodes will eventually be informed and this is what happens when the node is in this state when the node receives addjob commands it performs external replication like when a node is near the memory limits this means that it will make sure to create the number of replicas of the message in the cluster without using itself as a replica so no new messages are created in the context of a node which is leaving the node starts to send leaving messages to all clients that use getjob but would block waiting for jobs the leaving error means the clients should connect to another node clients that were already blocked waiting for messages will be unblocked and a leaving error will be sent to them as well the node no longer sends needjobs messages in the context of disque federation so it will never ask other nodes to transfer messages to it the node and all the other nodes will advertise it with a bad priority in the hello command output so that clients will select a different node the node will no longer create dummy acks in response to an ackjob command about a job it does not know all these behavior changes result in the node participating only as a source of messages so eventually its message count will drop to zero it is possible to check for this condition using info jobs when this happens the node can be stopped and removed from the other nodes tables using cluster forget as described in the section above client libraries disque uses the same protocol as redis itself to adapt redis clients or to use them directly should be pretty easy however note that disques default port is 7711 and not 6379 while a vanilla redis client may work well with disque clients should optionally use the following protocol in order to connect with a disque cluster the client should be given a number of ip addresses and ports where nodes are located the client should select random nodes and should try to connect until an available one is found on a successful connection the hello command should be used in order to retrieve the node id and other potentially useful information server version number of nodes if a consumer sees a high message rate received from foreign nodes it may optionally have logic in order to retrieve messages directly from the nodes where producers are producing the messages for a given topic the consumer can easily check the source of the messages by checking the node id prefix in the messages ids the getjob command or other commands may return a leaving error instead of blocking this error should be considered by the client library as a request to connect to a different node since the node it is connected to is not able to serve the request since it is leaving the cluster nodes in this state have a very high priority number published via hello so will be unlikely to be picked at the next connection attempt this way producers and consumers will eventually try to minimize node message exchanges whenever possible so basically you could perform basic usage using just a redis client however there are already specialized client libraries implementing a more specialized api on top of disque c disque c client common lisp cl disque elixir exdisque erlang edisque go disque go go disque disque java jedisque spinach node js disque js thunk disque disqueue node perl perl disque php phpque php hhvm disque php composer packagist disque client php composer packagist phloppy composer packagist python disq pypi pydisque pypi django q pypi ruby disque rb disque jockey disc rust disque rs net disque net implementation details job replication strategy disque tries to replicate to w 1 or w during out of memory reachable nodes shuffled the cluster repljob message is used to replicate a job to multiple nodes the job is sent together with the list of nodes that may have a copy if the required replication is not reached promptly the job is send to one additional node every 50 milliseconds when this happens a new repljob message is also re sent to each node that may already have a copy in order to refresh the list of nodes that have a copy if the specified synchronous replication timeout is reached the node that originally received the addjob command from the client gives up and returns an error to the client when this happens the node performs a best effort procedure to delete the job from nodes that may have already received a copy of the job cluster topology disque is a full mesh with each node connected to each other disque performs distributed failure detection via gossip only in order to adjust the replication strategy try reachable nodes first when trying to replicate a message and in order to inform clients about non reachable nodes when they want the list of nodes they can connect to as disque is multi master the event of nodes failing is not handled in any special way cluster messages nodes communicate via a set of messages using the node to node message bus a few of the messages are used in order to check that other nodes are reachable and to mark nodes as failing those messages are ping pong and fail since failure detection is only used to adjust the replication strategy talk with reachable nodes first in order to improve latency the details are yet not described other messages are more important since they are used in order to replicate jobs re issue jobs while trying to minimize multiple deliveries and in order to auto federate to serve consumers when messages are produced in different nodes compared to where consumers are the following is a list of messages and what they do split by category note that this is just an informal description while in the next sections describing the disque state machine there is a more detailed description of the behavior caused by message reception and in what cases they are generated cluster messages related to jobs replication and queueing repljob ask the receiver to replicate a job that is to add a copy of the job among the registered jobs in the target node when a job is accepted the receiver replies with gotjob to the sender a job may not be accepted if the receiving node is near out of memory in this case gotjob is not sent and the message discarded gotjob the reply to repljob to confirm the job was replicated enqueue ask a node to put a given job into its queue this message is used when a job is created by a node that does not want to take a copy so it asks another node among the ones that acknowledged the job replication to queue it for the first time if this message is lost after the retry time some node will try to re queue the message unless retry is set to zero willqueue this message is sent 500 milliseconds before a job is re queued to all the nodes that may have a copy of the message according to the sender table if some of the receivers already have the job queued theyll reply with queued in order to prevent the sender to queue the job again avoid multiple delivery when possible queued when a node re queues a job it sends queued to all the nodes that may have a copy of the message so that the other nodes will update the time at which theyll retry to queue the job moreover every node that already has the same job in queue but with a node id which is lexicographically smaller than the sending node will de queue the message in order to best effort de dup messages that may be queued in multiple nodes at the same time cluster messages related to ack propagation and garbage collection setack this message is sent to force a node to mark a job as successfully delivered acknowledged by the worker the job will no longer be considered active and will never be re queued by the receiving node also setack is send to the sender if the receiver of queued or willqueue message has the same job marked as acknowledged successfully delivered already gotack this message is sent in order to acknowledge a setack message the receiver can mark a given node that may have a copy of a job as informed about the fact that the job was acknowledged by the worker nodes delete garbage collect a message cluster wide when they believe all the nodes that may have a copy are informed about the fact the job was acknowledged deljob ask the receiver to remove a job is only sent in order to perform garbage collection of jobs by nodes that are sure the job was already delivered correctly usually the node sending deljob only does that when its sure that all the nodes that may have a copy of the message already marked the message ad delivered however after some time the job gc may be performed anyway in order to reclaim memory and in that case an otherwise avoidable multiple delivery of a job may happen the deljob message is also used in order to implement fast acknowledges cluster messages related to nodes federation needjobs queue count the sender asks the receiver to obtain messages for a given queue possibly count messages but this is only an hit for congestion control and messages optimization the receiver is free to reply with whatever number of messages needjobs messages are delivered in two ways broadcasted to every node in the cluster from time to time in order to discover new source nodes for a given queue or more often to a set of nodes that recently replies with jobs for a given queue this latter mechanism is called an ad hoc delivery and is possible since every node remembers for some time the set of nodes that were recent providers of messages for a given queue in both cases needjobs messages are delivered with exponential delays with the exception of queues that drop to zero messages and have a positive recent import rate in this case an ad hoc needjobs delivery is performed regardless of the last time the message was delivered in order to allow a continuous stream of messages under load yourjobs array of messages the reply to needjobs an array of serialized jobs usually all about the same queue but future optimization may allow to send different jobs from different queues jobs into yourjobs replies are extracted from the local queue and queued at the receiver nodes queue with the same name so even messages with a retry set to 0 at most once delivery still guarantee the safety rule since a given message may be in the source node on the wire or already received in the destination node if a yourjobs message is lost at least once delivery jobs will be re queued later when the retry time is reached disque state machine this section shows the most interesting as in less obvious parts of the state machine each disque node implements while practically it is a single state machine it is split in sections the state machine description uses a convention that is not standard but should look familiar since it is event driven made of actions performed upon message receptions in the form of commands received from clients messages received from other cluster nodes timers and procedure calls note that job is a job object with the following fields job delivered a list of nodes that may have this message this list does not need to be complete is used for best effort algorithms job confirmed a list of nodes that confirmed reception of ack by replying with a gotjob message job id the job 48 chars id job state the job state among wait repl active queued acked job replicate replication factor for this job job qtime time at which we need to re queue the job list fields such as delivered and confirmed support methods like size to get the number of elements states are as follows wait repl the job is waiting to be synchronously replicated active the job is active either it reached the replication factor in the originating node or it was created because the node received an repljob message from another node queued the job is active and also is pending into a queue in this node acked the job is no longer active since a client confirmed the reception using the ackjob command or another disque node sent a setack message for the job generic functions procedure lookup job string job id if job with the specified id is found returns the corresponding job object otherwise returns null procedure unregister object job delete the job from memory and if queued from the queue procedure enqueue job if job state queued return asap add job into job queue change job state to queued procedure dequeue job if job state queued return asap remove job from job queue change job state to active on recv cluster message deljob string job id job call lookup job job id if job null then call unregister job job replication state machine this part of the state machine documents how clients add jobs to the cluster and how the cluster replicates jobs across different disque nodes on recv client command addjob string queue name string body integer replicate integer retry integer ttl create a job object in wait repl state having as body ttl retry queue name the specified values send repljob job serialized cluster message to replicate 1 nodes block the client without replying step 3 well reply to the client in step 4 of gotjob message processing on recv cluster message repljob object serialized job job call lookup job serialized job id if job null then job delivered union job delivered serialized job delivered return asap since we have the job create a job from serialized job information job state active reply to the sender with gotjob job id step 1 we may already have the job since repljob may be duplicated step 2 if we already have the same job we update the list of jobs that may have a copy of this job performing the union of the list of nodes we have with the list of nodes in the serialized job on recv cluster message gotjob object serialized job job call lookup job serialized job id if job null or job state wait repl return asap add sender node to job confirmed if job confirmed size job replicate then change job state to active call enqueue job and reply to the blocked client with job id step 4 as we receive enough confirmations via gotjob messages we finally reach the replication factor required by the user and consider the message active timer firing every next 50 milliseconds while a job still did not reached the expected replication factor select an additional node not already listed in job delivered call it node add node to job delivered send repljob job serialized cluster message to each node in job delivered step 3 we send the message to every node again so that each node will have a chance to update job delivered with the new nodes it is not required for each node to know the full list of nodes that may have a copy but doing so improves our approximation of single delivery whenever possible job re queueing state machine this part of the state machine documents how disque nodes put a given job back into the queue after the specified retry time elapsed without the job being acknowledged timer firing 500 milliseconds before the retry time elapses send willqueue job id to every node in jobs delivered timer firing when job qtime time is reached if job retry 0 then return asap call enqueue job update job qtime to now job retry send queued job id message to each node in job delivered step 1 at most once jobs never get enqueued again step 3 well retry again after the retry period on recv cluster message willqueue string job id job call lookup job job id if job null then return asap if job state queued send queued job id to job delivered if job state acked send setack job id to the sender step 3 we broadcast the message since likely the other nodes are going to retry as well step 4 setack processing is documented below in the acknowledges section of the state machine description on recv cluster message queued string job id job call lookup job job id if job null then return asap if job state acked then return asap if job state queued then if sender node id is greater than my node id call dequeue job update job qtime setting it to now job retry step 4 if multiple nodes re queue the job about at the same time because of race conditions or network partitions that make willqueue not effective then queued forces receiving nodes to dequeue the message if the sender has a greater node id lowering the probability of unwanted multiple delivery step 5 now the message is already queued somewhere else but the node will retry again after the retry time acknowledged jobs garbage collection state machine this part of the state machine is used in order to garbage collect acknowledged jobs when a job finally gets acknowledged by a client procedure ack job job if job state is already acked do nothing and return asap change job state to acked dequeue the job if queued schedule first call to timer procedure start gc job send setack job delivered size to each node that is listed in job delivered but is not listed in job confirmed if job delivered size 0 then send setack 0 to every node in the cluster step 2 this is an ack about a job we dont know in that case we can just broadcast the acknowledged hoping somebody knows about the job and replies on recv client command ackjob string job id job call lookup job job id if job is null ignore the message and return call ack job job call start gc job on recv cluster message setack string job id integer may have job call lookup job job id call ack job job if job is not null reply with gotack if job null or job delivered size may have if job null and jobs delivered size may have then call start gc job if may have 0 and job null reply with gotack 1 and call start gc job steps 3 and 4 makes sure that among the reachable nodes that may have a message garbage collection will be performed by the node that is aware of more nodes that may have a copy step 5 instead is used in order to start a gc attempt if we received a setack message from a node just hacking a dummy ack an acknowledge about a job it was not aware of on recv cluster message gotack string job id bool known job call lookup job job id return asap if job null call ack job job if known true and job delivered size 0 then add the sender node to job delivered if known true or known false and job delivered size 0 or known false and sender is an element of job delivered then add the sender node to jobs confirmed if job delivered size 0 and job delivered size job confirmed size then send deljob job id to every node in the job delivered list and call unregister job if job delivered 0 and known true then call unregister job if job delivered 0 and job confirmed size cluster size then call unregister job step 3 if job delivered size is zero it means that the node just holds a dummy ack for the job it means the node has an acknowledged job it created on the fly because a client acknowledged via ackjob command a job it was not aware of step 6 we dont have to hold a dummy acknowledged jobs if there are nodes that have the job already acknowledged step 7 this happens when nobody knows about a job like when a client acknowledged a wrong job id timer from time to time exponential backoff with random error for every acknowledged job in memory call start gc job limitations disque is new code not tested and will require quite some time to reach production quality it is likely very buggy and may contain wrong assumptions or tradeoffs as long as the software is non stable the api may change in random ways without prior notification it is possible that disque spends too much effort in approximating single delivery during failures the fast acknowledge concept and command makes the user able to opt out this efforts but yet i may change the disque implementation and internals in the future if i see the user base really not caring about multiple deliveries during partitions there is yet a lot of redis dead code inside probably that could be removed disque was designed a bit in astronaut mode not triggered by an actual use case of mine but more in response to what i was seeing people doing with redis as a message queue and with other message queues however im not an expert if i succeeded to ship something useful for most users this is kinda of an accomplishment otherwise it may just be that disque is pretty useless as redis disque is single threaded while in redis there are stronger reasons to do so in disque there is no manipulation of complex data structures so maybe in the future it should be moved into a threaded server we need to see what happens in real use cases in order to understand if its worth it or not the number of jobs in a disque process is limited to the amount of memory available again while this in redis makes sense imho in disque there are definitely simple ways in order to circumvent this limitation like logging messages on disk when the server is out of memory and consuming back the messages when memory pressure is already acceptable however in general like in redis manipulating data structures in memory is a big advantage from the point of view of the implementation simplicity and the functionality we can provide to users disque is completely not optimized for speed was never profiled so far im currently not aware of the fact its slow fast or average compared to other messaging solutions for sure it is not going to have redis alike numbers because it does a lot more work at each command for example when a job is added it is serialized and transmitted to other n servers there is a lot more message passing between nodes involved and so forth the good news is that being totally unoptimized there is room for improvements ability of federation to handle well low and high loads without incurring into congestion or high latency was not tested well enough the algorithm is reasonable but may fail short under many load patterns amount of tested code path and possible states is not enough faq is disque part of redis no it is a standalone project however a big part of the redis networking source code nodes message bus libraries and the client protocol were reused in this new project in theory it was possible to extract the common code and release it as a framework to write distributed systems in c however this is not a perfect solution as well since the projects are expected to diverge more and more in the future and to rely on a common foundation was hard moreover the initial effort to turn redis into two different layers an abstract server networking stack and cluster bus and the actual redis implementation was a huge effort ways bigger than writing disque itself however while it is a separated project conceptually disque is related to redis since it tries to solve a redis use case in a vertical ad hoc way who created disque disque is a side project of salvatore sanfilippo aka antirez there are chances for this project to be actively developed currently i consider this just a public alpha if i see people happy to use it for the right reasons i e it is better in some use cases compared to other message queues ill continue the development otherwise it was anyway cool to develop it i had much fun and i definitely learned new things what happens when a node runs out of memory maxmemory setting is mandatory in disque and defaults to 1gb when 75 of maxmemory is reached disque starts to replicate the new jobs only to external nodes without taking a local copy so basically if there is free ram into other nodes adding still works when 95 of maxmemory is reached disque starts to evict data that does not violates the safety guarantees for instance acknowledged jobs and inactive queues when 100 of maxmemory is reached commands that may result into more memory used are not processed at all and the client is informed with an error are there plans to add the ability to hold more jobs than the physical memory of a single node can handle yes in disque it should be relatively simple to use the disk when memory is not available since jobs are immutable and dont need to necessarily exist in memory at a given time there are multiple strategies available the current idea is that when an instance is out of memory jobs are stored into a log file instead of memory as more free memory is available in the instance on disk jobs are loaded however in order to implement this there is to observe strong evidence of its general usefulness for the user base when i consume and produce from different nodes sometimes there is a delay in order for the jobs to reach the consumer why disque routing is not static the cluster automatically tries to provide messages to nodes where consumers are attached when there is an high enough traffic even one message per second is enough nodes remember other nodes that recently were sources for jobs in a given queue so it is possible to aggressively send messages asking for more jobs every time there are consumers waiting for more messages and the local queue is empty however when the traffic is very low informations about recent sources of messages are discarded and nodes rely on a more generic mechanism in order to discover other nodes that may have messages in the queues we need them which is also used in high traffic conditions as well in order to discover new sources of messages for a given queue for example imagine a setup with two nodes a and b a client attaches to node a and asks for jobs in the queue myqueue node a has no jobs enqueued so the client is blocked after a few seconds another client produces messages into myqueue but sending them to node b during step 1 if there was no recent traffic of imported messages for this queue node a has no idea about who may have messages for the queue myqueue every other node may have or none may have so it starts to broadcast needjobs messages to the whole cluster however we cant spam the cluster with messages so if no reply is received after the first broadcast the next will be sent with a larger delay and so foth the delay is exponential with a maximum value of 30 seconds this parameters will be configurable in the future likely when there is some traffic instead nodes send needjobs messages asap to other nodes that were recent sources of messages even when no reply is received the next needjobs messages will be sent more aggressively to the subset of nodes that had messages in the past with a delay that starts at 25 milliseconds and has a maximum value of two seconds in order to minimize the latency needjobs messages are not throttled at all when a client consumed the last message from a given queue source nodes are informed immediately in order to receive messages before the node asks for more blocked clients are served the last message available in the queue for more information please refer to the file queue c especially the function needjobsforqueue and its callers are messages re enqueued in the queue tail or head or what messages are put into the queue according to their creation time attribute this means that they are enqueued in a best effort order in the local node queue messages that need to be put back into the queue again because their delivery failed are usually but not always older than messages already in queue so theyll likely be among the first to be delivered to workers what disque means distributed queue but is also a joke with dis as negation like in disorder of the strict concept of queue since disque is not able to guarantee the strict ordering you expect from something called queue and because of this tradeof it gains many other interesting things community how to get help and how to help get in touch with us in one of the following ways post on stack overflow using the disque tag this is the preferred method to get general help about disque other users will easily find previous questions so we can incrementally build a knowledge base join the disque irc channel at irc freenode net create an issue or pull request if your question or issue is about the disque implementation itself thanks i would like to say thank you to the following persons and companies pivotal for allowing me to work on disque most in my spare time but sometimes during work hours moreover pivotal agreed to leave the copyright of the code to me this is very generous thanks pivotal michel martens and damian janowski for providing early feedback about disque while the project was still private everybody who is already writing client libraries sending pull requests creating issues in order to move this forward from alpha to something actually usable