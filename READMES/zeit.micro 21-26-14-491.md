micro â€” asynchronous http microservices features easy designed for usage with async and await more fast ultra high performance even json parsing is opt in micro the whole project is 260 lines of code agile super easy deployment and containerization simple oriented for single purpose modules function standard just http explicit no middleware modules declare all dependencies lightweight with all dependencies the package weighs less than a megabyte installation important micro is only meant to be used in production in development you should use micro dev which provides you with a tool belt specifically tailored for developing microservices to prepare your microservice for running in the production environment firstly install micro bash npm install save micro usage create an index js file and export a function that accepts the standard http incomingmessage and http serverresponse objects js module exports req res res end welcome to micro micro provides useful helpers but also handles return values â€“ so you can write it even shorter js module exports welcome to micro next ensure that the main property inside package json points to your microservice which is inside index js in this example case and add a start script json main index js scripts start micro once all of that is done the server can be started like this bash npm start and go to this url http localhost 3000 ðŸŽ‰ command line micro asynchronous http microservices usage micro help micro version micro l listen uri l entry point js by default micro will listen on 0 0 0 0 3000 and will look first for the main property in package json and subsequently for index js as the default entry point specifying a single listen argument will overwrite the default not supplement it options help shows this help message v version displays the current version of micro l listen listen uri specify a uri endpoint on which to listen see below more than one may be specified to listen in multiple places endpoints listen endpoints specified by the listen or l options above instruct micro to listen on one or more interfaces ports unix domain sockets or windows named pipes for tcp traditional host port endpoints micro l tcp hostname 1234 for unix domain socket endpoints micro l unix path to socket sock for windows named pipe endpoints micro l pipe \\ \pipe\pipename async await examples fetch external api micro is built for usage with async await you can read more about async await here js const sleep require then sleep module exports async req res await sleep 500 return ready transpilation the package takes advantage of native support for async and await which is available as of node js 8 0 0 in turn we suggest either using at least this version both in development and production if possible or transpiling the code using async to gen if you cant use the latest node js version in order to do that you firstly need to install it bash npm install save async to gen and then add the transpilation command to the scripts build property inside package json json scripts build async to gen input js output js once these two steps are done you can transpile the code by running this command bash npm run build thats all it takes to transpile by yourself but just to be clear only do this if you cant use node js 8 0 0 if you can async and await will just work right out of the box port based on environment variable when you want to set the port using an environment variable you can use micro l tcp 0 0 0 0 port optionally you can add a default if it suits your use case micro l tcp 0 0 0 0 port 3000 port 3000 will allow a fallback to port 3000 when port is not defined note that this only works in bash body parsing examples parse json parse urlencoded form html form tag for parsing the incoming request body we included an async functions buffer text and json js const buffer text json require micro module exports async req res const buf await buffer req console log buf const txt await text req console log txt price 9 99 const js await json req console log js price 9 99 return api buffer req limit 1mb encoding utf8 text req limit 1mb encoding utf8 json req limit 1mb encoding utf8 buffers and parses the incoming body and returns it exposes an async function that can be run with await can be called multiple times as it caches the raw request body the first time limit is how much data is aggregated before parsing at max otherwise an error is thrown with statuscode set to 413 see error handling it can be a number of bytes or a string like 1mb if json parsing fails an error is thrown with statuscode set to 400 see error handling for other types of data check the examples sending a different status code so far we have used return to send data to the client return hello world is the equivalent of send res 200 hello world js const send require micro module exports async req res const statuscode 400 const data error custom error message send res statuscode data send res statuscode data null use require micro send statuscode is a number with the http status code and must always be supplied if data is supplied it is sent in the response different input types are processed appropriately and content type and content length are automatically set stream data is piped as an octet stream note it is your responsibility to handle the error event in this case usually simply logging the error and aborting the response is enough buffer data is written as an octet stream object data is serialized as json string data is written as is if json serialization fails for example if a cyclical reference is found a 400 error is thrown see error handling programmatic use you can use micro programmatically by requiring micro directly js const micro require micro const sleep require then sleep const server micro async req res await sleep 500 return hello world server listen 3000 micro fn this function is exposed as the default export use require micro returns a http server that uses the provided function as the request handler the supplied function is run with await so it can be async senderror req res error use require micro senderror used as the default handler for errors thrown automatically sets the status code of the response based on error statuscode sends the error message as the body stacks are printed out with console error and during development when node env is set to development also sent in responses usually you dont need to invoke this method yourself as you can use the built in error handling flow with throw createerror code msg orig use require micro createerror creates an error object with a statuscode useful for easily throwing errors with http status codes which are interpreted by the built in error handling orig sets error originalerror which identifies the original error if any error handling micro allows you to write robust microservices this is accomplished primarily by bringing sanity back to error handling and avoiding callback soup if an error is thrown and not caught by you the response will automatically be 500 important error stacks will be printed as console error and during development mode if the env variable node env is development they will also be included in the responses if the error object thats thrown contains a statuscode property thats used as the http code to be sent lets say you want to write a rate limiting module js const ratelimit require my rate limit module exports async req res await ratelimit req your code if the api endpoint is abused it can throw an error with createerror like so js if toomany throw createerror 429 rate limit exceeded alternatively you can create the error object yourself js if toomany const err new error rate limit exceeded err statuscode 429 throw err the nice thing about this model is that the statuscode is merely a suggestion the user can override it js try await ratelimit req catch err if 429 err statuscode perhaps send 500 instead send res 500 if the error is based on another error that micro caught like a json parse exception then originalerror will point to it if a generic error is caught the status will be set to 500 in order to set up your own error handling mechanism you can use composition in your handler js const send require micro const handleerrors fn async req res try return await fn req res catch err console log err stack send res 500 my custom error module exports handleerrors async req res throw new error what happened here testing micro makes tests compact and a pleasure to read and write we recommend ava a highly parallel micro test framework with built in support for async tests js const micro require micro const test require ava const listen require test listen const request require request promise test my endpoint async t const service micro async req res micro send res 200 test woot const url await listen service const body await request url t deepequal json parse body test woot service close look at test listen for a function that returns a url with an ephemeral port every time its called contributing fork this repository to your own github account and then clone it to your local device link the package to the global module directory npm link within the module you want to test your local development instance of micro just link it to the dependencies npm link micro instead of the default one from npm node will now use your clone of micro as always you can run the ava and eslint tests using npm test credits thanks to tom yandell and richard hodgson for donating the name micro on npm authors guillermo rauch rauchg zeit leo lamprecht notquiteleo zeit tim neutkens timneutkens zeit