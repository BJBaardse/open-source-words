neural style this is a torch implementation of the paper a neural algorithm of artistic style by leon a gatys alexander s ecker and matthias bethge the paper presents an algorithm for combining the content of one image with the style of another image using convolutional neural networks heres an example that maps the artistic style of the starry night onto a night time photograph of the stanford campus applying the style of different images to the same content image gives interesting results here we reproduce figure 2 from the paper which renders a photograph of the tubingen in germany in a variety of styles here are the results of applying the style of various pieces of artwork to this photograph of the golden gate bridge content style tradeoff the algorithm allows the user to trade off the relative weight of the style and content reconstruction terms as shown in this example where we port the style of picassos 1907 self portrait onto brad pitt style scale by resizing the style image before extracting style features we can control the types of artistic features that are transfered from the style image you can control this behavior with the style scale flag below we see three examples of rendering the golden gate bridge in the style of the starry night from left to right style scale is 2 0 1 0 and 0 5 multiple style images you can use more than one style image to blend multiple artistic styles clockwise from upper left the starry night the scream the scream composition vii seated nude composition vii and seated nude the starry night style interpolation when using multiple style images you can control the degree to which they are blended transfer style but not color if you add the flag original colors 1 then the output image will retain the colors of the original image this is similar to the recent blog post by deepart io setup dependencies torch7 loadcaffe optional dependencies for cuda backend cuda 6 5 cunn for cudnn backend cudnn torch for opencl backend cltorch clnn after installing dependencies youll need to run the following script to download the vgg model sh models download models sh this will download the original vgg 19 model leon gatys has graciously provided the modified version of the vgg 19 model that was used in their paper this will also be downloaded by default the original vgg 19 model is used if you have a smaller memory gpu then using nin imagenet model will be better and gives slightly worse yet comparable results you can get the details on the model from bvlc caffe modelzoo and can download the files from nin imagenet download link you can find detailed installation instructions for ubuntu in the installation guide usage basic usage th neural style lua style image image jpg content image image jpg opencl usage with nin model this requires you download the nin imagenet model files as described above th neural style lua style image examples inputs picasso selfport1907 jpg content image examples inputs brad pitt jpg output image profile png model file models nin imagenet conv caffemodel proto file models train val prototxt gpu 0 backend clnn num iterations 1000 seed 123 content layers relu0 relu3 relu7 relu12 style layers relu0 relu3 relu7 relu12 content weight 10 style weight 1000 image size 512 optimizer adam to use multiple style images pass a comma separated list like this style image starry night jpg the scream jpg note that paths to images should not contain the character to represent your home directory you should instead use a relative path or a full absolute path options image size maximum side length in pixels of of the generated image default is 512 style blend weights the weight for blending the style of multiple style images as a comma separated list such as style blend weights 3 7 by default all style images are equally weighted gpu zero indexed id of the gpu to use for cpu mode set gpu to 1 optimization options content weight how much to weight the content reconstruction term default is 5e0 style weight how much to weight the style reconstruction term default is 1e2 tv weight weight of total variation tv regularization this helps to smooth the image default is 1e 3 set to 0 to disable tv regularization num iterations default is 1000 init method for generating the generated image one of random or image default is random which uses a noise initialization as in the paper image initializes with the content image optimizer the optimization algorithm to use either lbfgs or adam default is lbfgs l bfgs tends to give better results but uses more memory switching to adam will reduce memory usage when using adam you will probably need to play with other parameters to get good results especially the style weight content weight and learning rate you may also want to normalize gradients when using adam learning rate learning rate to use with the adam optimizer default is 1e1 normalize gradients if this flag is present style and content gradients from each layer will be l1 normalized idea from andersbll neural artistic style output options output image name of the output image default is out png print iter print progress every print iter iterations set to 0 to disable printing save iter save the image every save iter iterations set to 0 to disable saving intermediate results layer options content layers comma separated list of layer names to use for content reconstruction default is relu4 2 style layers comma separated list of layer names to use for style reconstruction default is relu1 1 relu2 1 relu3 1 relu4 1 relu5 1 other options style scale scale at which to extract features from the style image default is 1 0 original colors if you set this to 1 then the output image will keep the colors of the content image proto file path to the deploy txt file for the vgg caffe model model file path to the caffemodel file for the vgg caffe model default is the original vgg 19 model you can also try the normalized vgg 19 model used in the paper pooling the type of pooling layers to use one of max or avg default is max the vgg 19 models uses max pooling layers but the paper mentions that replacing these layers with average pooling layers can improve the results i havent been able to get good results using average pooling but the option is here backend nn cudnn or clnn default is nn cudnn requires cudnn torch and may reduce memory usage clnn requires cltorch and clnn cudnn autotune when using the cudnn backend pass this flag to use the built in cudnn autotuner to select the best convolution algorithms for your architecture this will make the first iteration a bit slower and can take a bit more memory but may significantly speed up the cudnn backend frequently asked questions problem generated image has saturation artifacts solution update the image packge to the latest version luarocks install image problem running without a gpu gives an error message complaining about cutorch not found solution pass the flag gpu 1 when running in cpu only mode problem the program runs out of memory and dies solution try reducing the image size image size 256 or lower note that different image sizes will likely require non default values for style weight and content weight for optimal results if you are running on a gpu you can also try running with backend cudnn to reduce memory usage problem get the following error message models vgg ilsvrc 19 layers deploy prototxt cpu lua 7 attempt to call method ceil a nil value solution update nn package to the latest version luarocks install nn problem get an error message complaining about paths extname solution update torch paths package to the latest version luarocks install paths problem nin imagenet model is not giving good results solution make sure the correct proto file is selected also make sure the correct parameters for content layers and style layers are set see opencl usage example above problem backend cudnn is slower than default nn backend solution add the flag cudnn autotune this will use the built in cudnn autotuner to select the best convolution algorithms memory usage by default neural style uses the nn backend for convolutions and l bfgs for optimization these give good results but can both use a lot of memory you can reduce memory usage with the following use cudnn add the flag backend cudnn to use the cudnn backend this will only work in gpu mode use adam add the flag optimizer adam to use adam instead of l bfgs this should significantly reduce memory usage but may require tuning of other parameters for good results in particular you should play with the learning rate content weight style weight and also consider using gradient normalization this should work in both cpu and gpu modes reduce image size if the above tricks are not enough you can reduce the size of the generated image pass the flag image size 256 to generate an image at half the default size with the default settings neural style uses about 3 5gb of gpu memory on my system switching to adam and cudnn reduces the gpu memory footprint to about 1gb speed speed can vary a lot depending on the backend and the optimizer here are some times for running 500 iterations with image size 512 on a maxwell titan x with different settings backend nn optimizer lbfgs 62 seconds backend nn optimizer adam 49 seconds backend cudnn optimizer lbfgs 79 seconds backend cudnn cudnn autotune optimizer lbfgs 58 seconds backend cudnn cudnn autotune optimizer adam 44 seconds backend clnn optimizer lbfgs 169 seconds backend clnn optimizer adam 106 seconds here are the same benchmarks on a pascal titan x with cudnn 5 0 on cuda 8 0 rc backend nn optimizer lbfgs 43 seconds backend nn optimizer adam 36 seconds backend cudnn optimizer lbfgs 45 seconds backend cudnn cudnn autotune optimizer lbfgs 30 seconds backend cudnn cudnn autotune optimizer adam 22 seconds multi gpu scaling you can use multiple gpus to process images at higher resolutions different layers of the network will be computed on different gpus you can control which gpus are used with the gpu flag and you can control how to split layers across gpus using the multigpu strategy flag for example in a server with four gpus you can give the flag gpu 0 1 2 3 to process on gpus 0 1 2 and 3 in that order by also giving the flag multigpu strategy 3 6 12 you indicate that the first two layers should be computed on gpu 0 layers 3 to 5 should be computed on gpu 1 layers 6 to 11 should be computed on gpu 2 and the remaining layers should be computed on gpu 3 you will need to tune the multigpu strategy for your setup in order to achieve maximal resolution we can achieve very high quality results at high resolution by combining multi gpu processing with multiscale generation as described in the paper controlling perceptual factors in neural style transfer by leon a gatys alexander s ecker matthias bethge aaron hertzmann and eli shechtman here is a 3620 x 1905 image generated on a server with four pascal titan x gpus the script used to generate this image can be found here implementation details images are initialized with white noise and optimized using l bfgs we perform style reconstructions using the conv1 1 conv2 1 conv3 1 conv4 1 and conv5 1 layers and content reconstructions using the conv4 2 layer as in the paper the five style reconstruction losses have equal weights citation if you find this code useful for your research please cite misc johnson2015 author johnson justin title neural style year 2015 publisher github journal github repository howpublished \url https github com jcjohnson neural style