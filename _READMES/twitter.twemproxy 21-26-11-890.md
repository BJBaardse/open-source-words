twemproxy nutcracker twemproxy pronounced two em proxy aka nutcracker is a fast and lightweight proxy for memcached and redis protocol it was built primarily to reduce the number of connections to the caching servers on the backend this together with protocol pipelining and sharding enables you to horizontally scale your distributed caching architecture build to build twemproxy from distribution tarball configure make sudo make install to build twemproxy from distribution tarball in debug mode cflags ggdb3 o0 configure enable debug full make sudo make install to build twemproxy from source with debug logs enabled and assertions enabled git clone git github com twitter twemproxy git cd twemproxy autoreconf fvi configure enable debug full make src nutcracker h a quick checklist use newer version of gcc older version of gcc has problems use cflags o1 configure make use cflags o3 fno strict aliasing configure make autoreconf fvi configure needs automake and libtool to be installed features fast lightweight maintains persistent server connections keeps connection count on the backend caching servers low enables pipelining of requests and responses supports proxying to multiple servers supports multiple server pools simultaneously shard data automatically across multiple servers implements the complete memcached ascii and redis protocol easy configuration of server pools through a yaml file supports multiple hashing modes including consistent hashing and distribution can be configured to disable nodes on failures observability via stats exposed on the stats monitoring port works with linux bsd os x and smartos solaris help usage nutcracker hvddt v verbosity level o output file c conf file s stats port a stats addr i stats interval p pid file m mbuf size options h help this help v version show version and exit t test conf test configuration for syntax errors and exit d daemonize run as a daemon d describe stats print stats description and exit v verbose n set logging level default 5 min 0 max 11 o output s set logging file default stderr c conf file s set configuration file default conf nutcracker yml s stats port n set stats monitoring port default 22222 a stats addr s set stats monitoring ip default 0 0 0 0 i stats interval n set stats aggregation interval in msec default 30000 msec p pid file s set pid file default off m mbuf size n set size of mbuf chunk in bytes default 16384 bytes zero copy in twemproxy all the memory for incoming requests and outgoing responses is allocated in mbuf mbuf enables zero copy because the same buffer on which a request was received from the client is used for forwarding it to the server similarly the same mbuf on which a response was received from the server is used for forwarding it to the client furthermore memory for mbufs is managed using a reuse pool this means that once mbuf is allocated it is not deallocated but just put back into the reuse pool by default each mbuf chunk is set to 16k bytes in size there is a trade off between the mbuf size and number of concurrent connections twemproxy can support a large mbuf size reduces the number of read syscalls made by twemproxy when reading requests or responses however with a large mbuf size every active connection would use up 16k bytes of buffer which might be an issue when twemproxy is handling large number of concurrent connections from clients when twemproxy is meant to handle a large number of concurrent client connections you should set chunk size to a small value like 512 bytes using the m or mbuf size n argument configuration twemproxy can be configured through a yaml file specified by the c or conf file command line argument on process start the configuration file is used to specify the server pools and the servers within each pool that twemproxy manages the configuration files parses and understands the following keys listen the listening address and port name port or ip port or an absolute path to sock file e g var run nutcracker sock for this server pool client connections the maximum number of connections allowed from redis clients unlimited by default though os imposed limitations will still apply hash the name of the hash function possible values are one at a time md5 crc16 crc32 crc32 implementation compatible with libmemcached crc32a correct crc32 implementation as per the spec fnv1 64 fnv1a 64 fnv1 32 fnv1a 32 hsieh murmur jenkins hash tag a two character string that specifies the part of the key used for hashing eg or hash tag enable mapping different keys to the same server as long as the part of the key within the tag is the same distribution the key distribution mode possible values are ketama modula random timeout the timeout value in msec that we wait for to establish a connection to the server or receive a response from a server by default we wait indefinitely backlog the tcp backlog argument defaults to 512 preconnect a boolean value that controls if twemproxy should preconnect to all the servers in this pool on process start defaults to false redis a boolean value that controls if a server pool speaks redis or memcached protocol defaults to false redis auth authenticate to the redis server on connect redis db the db number to use on the pool servers defaults to 0 note twemproxy will always present itself to clients as db 0 server connections the maximum number of connections that can be opened to each server by default we open at most 1 server connection auto eject hosts a boolean value that controls if server should be ejected temporarily when it fails consecutively server failure limit times see liveness recommendations for information defaults to false server retry timeout the timeout value in msec to wait for before retrying on a temporarily ejected server when auto eject host is set to true defaults to 30000 msec server failure limit the number of consecutive failures on a server that would lead to it being temporarily ejected when auto eject host is set to true defaults to 2 servers a list of server address port and weight name port weight or ip port weight for this server pool for example the configuration file in conf nutcracker yml also shown below configures 5 server pools with names alpha beta gamma delta and omega clients that intend to send requests to one of the 10 servers in pool delta connect to port 22124 on 127 0 0 1 clients that intend to send request to one of 2 servers in pool omega connect to unix path tmp gamma requests sent to pool alpha and omega have no timeout and might require timeout functionality to be implemented on the client side on the other hand requests sent to pool beta gamma and delta timeout after 400 msec 400 msec and 100 msec respectively when no response is received from the server of the 5 server pools only pools alpha gamma and delta are configured to use server ejection and hence are resilient to server failures all the 5 server pools use ketama consistent hashing for key distribution with the key hasher for pools alpha beta gamma and delta set to fnv1a 64 while that for pool omega set to hsieh also only pool beta uses nodes names for consistent hashing while pool alpha gamma delta and omega use host port weight for consistent hashing finally only pool alpha and beta can speak the redis protocol while pool gamma delta and omega speak memcached protocol alpha listen 127 0 0 1 22121 hash fnv1a 64 distribution ketama auto eject hosts true redis true server retry timeout 2000 server failure limit 1 servers 127 0 0 1 6379 1 beta listen 127 0 0 1 22122 hash fnv1a 64 hash tag distribution ketama auto eject hosts false timeout 400 redis true servers 127 0 0 1 6380 1 server1 127 0 0 1 6381 1 server2 127 0 0 1 6382 1 server3 127 0 0 1 6383 1 server4 gamma listen 127 0 0 1 22123 hash fnv1a 64 distribution ketama timeout 400 backlog 1024 preconnect true auto eject hosts true server retry timeout 2000 server failure limit 3 servers 127 0 0 1 11212 1 127 0 0 1 11213 1 delta listen 127 0 0 1 22124 hash fnv1a 64 distribution ketama timeout 100 auto eject hosts true server retry timeout 2000 server failure limit 1 servers 127 0 0 1 11214 1 127 0 0 1 11215 1 127 0 0 1 11216 1 127 0 0 1 11217 1 127 0 0 1 11218 1 127 0 0 1 11219 1 127 0 0 1 11220 1 127 0 0 1 11221 1 127 0 0 1 11222 1 127 0 0 1 11223 1 omega listen tmp gamma 0666 hash hsieh distribution ketama auto eject hosts false servers 127 0 0 1 11214 100000 127 0 0 1 11215 1 finally to make writing a syntactically correct configuration file easier twemproxy provides a command line argument t or test conf that can be used to test the yaml configuration file for any syntax error observability observability in twemproxy is through logs and stats twemproxy exposes stats at the granularity of server pool and servers per pool through the stats monitoring port the stats are essentially json formatted key value pairs with the keys corresponding to counter names by default stats are exposed on port 22222 and aggregated every 30 seconds both these values can be configured on program start using the c or conf file and i or stats interval command line arguments respectively you can print the description of all stats exported by using the d or describe stats command line argument nutcracker describe stats pool stats client eof eof on client connections client err errors on client connections client connections active client connections server ejects times backend server was ejected forward error times we encountered a forwarding error fragments fragments created from a multi vector request server stats server eof eof on server connections server err errors on server connections server timedout timeouts on server connections server connections active server connections requests requests request bytes total request bytes responses responses response bytes total response bytes in queue requests in incoming queue in queue bytes current request bytes in incoming queue out queue requests in outgoing queue out queue bytes current request bytes in outgoing queue logging in twemproxy is only available when twemproxy is built with logging enabled by default logs are written to stderr twemproxy can also be configured to write logs to a specific file through the o or output command line argument on a running twemproxy we can turn log levels up and down by sending it sigttin and sigttou signals respectively and reopen log files by sending it sighup signal pipelining twemproxy enables proxying multiple client connections onto one or few server connections this architectural setup makes it ideal for pipelining requests and responses and hence saving on the round trip time for example if twemproxy is proxying three client connections onto a single server and we get requests get key\r\n set key 0 0 3\r\nval\r\n and delete key\r\n on these three connections respectively twemproxy would try to batch these requests and send them as a single message onto the server connection as get key\r\nset key 0 0 3\r\nval\r\ndelete key\r\n pipelining is the reason why twemproxy ends up doing better in terms of throughput even though it introduces an extra hop between the client and server deployment if you are deploying twemproxy in production you might consider reading through the recommendation document to understand the parameters you could tune in twemproxy to run it efficiently in the production environment packages ubuntu ppa stable https launchpad net twemproxy archive ubuntu stable ppa daily https launchpad net twemproxy archive ubuntu daily utils collectd plugin munin plugin twemproxy ganglia module nagios checks circonus puppet module nutcracker web redis twemproxy agent sensu metrics redis mgr smitty for twemproxy failover beholder a python agent for twemproxy failover chef cookbook twemsentinel https github com yak0 twemsentinel companies using twemproxy in production twitter wikimedia pinterest snapchat flickr yahoo tumblr vine wayfair kiip wuaki tv wanelo kontera bright 56 com digg gawkermedia 3scale net ooyala twitch socrata hootsuite trivago machinezone path aol soysuper vinted poshmark fanduel bloomreach hootsuite tradesy uber details greta issues and support have a bug or a question please create an issue here on github https github com twitter twemproxy issues committers manju rajashekhar manju lin yang idning thank you to all of our contributors license copyright 2012 twitter inc licensed under the apache license version 2 0 http www apache org licenses license 2 0