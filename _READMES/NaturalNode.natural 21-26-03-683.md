natural natural is a general natural language facility for nodejs tokenizing stemming classification phonetics tf idf wordnet string similarity and some inflections are currently supported its still in the early stages so were very interested in bug reports contributions and the like note that many algorithms from rob elliss node nltools are being merged into this project and will be maintained from here onward while most of the algorithms are english specific contributors have implemented support for other languages thanks to polyakov vladimir russian stemming has been added thanks to david przybilla spanish stemming has been added thanks to even more contributors stemming and tokenizing in more languages have been added aside from this readme the only documentation is this dzone article this free course on egghead io and here on my blog which is a bit older table of contents installation tokenizers string distance approximate string matching stemmers classifiers bayesian and logistic regression maximum entropy classifier sentiment analysis phonetics inflectors n grams tf idf tries edgeweighteddigraph shortestpathtree longestpathtree wordnet spellcheck pos tagger development license installation if youre just looking to use natural without your own node application you can install via npm like so npm install natural if youre interested in contributing to natural or just hacking on it then by all means fork away tokenizers word regexp and treebank tokenizers are provided for breaking text up into arrays of tokens javascript var natural require natural var tokenizer new natural wordtokenizer console log tokenizer tokenize your dog has fleas your dog has fleas the other tokenizers follow a similar pattern javascript tokenizer new natural treebankwordtokenizer console log tokenizer tokenize my dog hasnt any fleas my dog has n\t any fleas tokenizer new natural regexptokenizer pattern console log tokenizer tokenize flea dog flea dog tokenizer new natural wordpuncttokenizer console log tokenizer tokenize my dog hasnt any fleas my dog hasn \ t any fleas tokenizer new natural orthographytokenizer language fi console log tokenizer tokenize mikä sinun nimesi on mikä sinun nimesi on overview of available tokenizers tokenizer language explanation wordtokenizer any splits on anything except alphabetic characters digits and underscore wordpuncttokenizer any splits on anything except alphabetic characters digits punctuation and underscore sentencetokenizer any break string up in to parts based on punctation and quotation marks casetokenizer any if lower and upper case are the same the character is assumed to be whitespace or something else punctuation regexptokenizer any splits on a regular expression that either defines sequences of word characters or gap characters orthographytokenizer finnish splits on anything except alpabetic characters digits and underscore treebankwordtokenizer any aggressivetokenizer english aggressivetokenizerfa farsi aggressivetokenizerfr french aggressivetokenizerru russian aggressivetokenizeres spanish aggressivetokenizerit italian aggressivetokenizerpl polish aggressivetokenizerpt portugese aggressivetokenizerno norwegian aggressivetokenizersv swedish aggressivetokenizervi vietnamese tokenizerja japanese string distance natural provides an implementation of three algorithms for calculating string distance hamming distance jaro winkler levenshtein distance and dice coefficient hamming distance measures the distance between two strings of equal length by counting the number of different characters the third parameter indicates whether case should be ignored by default the algorithm is case sensitive javascript var natural require natural console log natural hammingdistance karolin kathrin false console log natural hammingdistance karolin kerstin false if strings differ in length 1 is returned console log natural hammingdistance short string longer string false output javascript 3 3 1 the jaro–winkler string distance measuring algorithm will return a number between 0 and 1 which tells how closely the strings match 0 not at all 1 exact match javascript var natural require natural console log natural jarowinklerdistance dixon dicksonx console log natural jarowinklerdistance not same output javascript 0 7466666666666666 0 if the distance between the strings is already known you can pass it as a third parameter and you can force the algorithm to ignore case by passing a fourth parameter as follows javascript var natural require natural console log natural jarowinklerdistance dixon dicksonx undefined true natural also offers support for levenshtein distances javascript var natural require natural console log natural levenshteindistance ones onez console log natural levenshteindistance one one output javascript 1 0 the cost of the three edit operations are modifiable for levenshtein javascript console log natural levenshteindistance ones onez insertion cost 1 deletion cost 1 substitution cost 1 output javascript 1 full damerau levenshtein matching can be used if you want to consider character transpositions as a valid edit operation javascript console log natural dameraulevenshteindistance az za output javascript 1 the transposition cost can be modified as well javascript console log natural dameraulevenshteindistance az za transposition cost 0 output javascript 0 a restricted form of damerau levenshtein optimal string alignment is available this form of matching is more space efficient than unrestricted damerau levenshtein by only considering a transposition if there are no characters between the transposed characters comparison javascript optimal string alignment console log natural dameraulevenshteindistance abc acb restricted true 1 console log natural dameraulevenshteindistance ca abc restricted true 2 unrestricted damerau levenshtein console log natural dameraulevenshteindistance ca abc restricted false 1 and dices co efficient javascript var natural require natural console log natural dicecoefficient thing thing console log natural dicecoefficient not same output javascript 1 0 approximate string matching currently matching is supported via the levenshtein algorithm javascript var natural require natural var source the raincoat bookstore var target all the best books are here at the rain coats book store console log natural levenshteindistance source target search true output javascript substring the rain coats book store distance 4 the following stemmers currently stemming is supported via the porter and lancaster paice husk algorithms the indonesian and japanese stemmers do not follow a known algorithm javascript var natural require natural this example uses a porter stemmer word is returned javascript console log natural porterstemmer stem words stem a single word in russian javascript console log natural porterstemmerru stem падший in spanish javascript console log natural porterstemmeres stem jugaría the following stemmers are available language porter lancaster other module dutch x porterstemmernl english x porterstemmer english x lancasterstemmer farsi in progress x porterstemmerfa french x porterstemmerfr indonesian x stemmerid italian x porterstemmerit japanese x stemmerja norwegian x porterstemmerno portugese x porterstemmerpt russian x porterstemmerru swedish x porterstemmersv attach patches stem and tokenizeandstem to string as a shortcut to porterstemmer stem token tokenizeandstem breaks text up into single words and returns an array of stemmed tokens javascript natural porterstemmer attach console log i am waking up to the sounds of chainsaws tokenizeandstem console log chainsaws stem the same thing can be done with a lancaster stemmer javascript natural lancasterstemmer attach console log i am waking up to the sounds of chainsaws tokenizeandstem console log chainsaws stem classifiers bayesian and logistic regression two classifiers are currently supported naive bayes and logistic regression the following examples use the bayesclassifier class but the logisticregressionclassifier class could be substituted instead javascript var natural require natural var classifier new natural bayesclassifier you can train the classifier on sample text it will use reasonable defaults to tokenize and stem the text javascript classifier adddocument i am long qqqq buy classifier adddocument buy the q\s buy classifier adddocument short gold sell classifier adddocument sell gold sell classifier train outputs sell javascript console log classifier classify i am short silver outputs buy javascript console log classifier classify i am long copper you have access to the set of matched classes and the associated value from the classifier outputs javascript label buy value 0 39999999999999997 label sell value 0 19999999999999998 from this javascript console log classifier getclassifications i am long copper the classifier can also be trained with and can classify arrays of tokens strings or any mixture of the two arrays let you use entirely custom data with your own tokenization stemming if you choose to implement it javascript classifier adddocument sell gold sell the training process can be monitored by subscribing to the event trainedwithdocument thats emitted by the classifier this events emitted each time a document is finished being trained against javascript classifier events on trainedwithdocument function obj console log obj total 23 there are 23 total documents being trained against index 12 the index number of the document thats just been trained against doc the document that has just been indexed a classifier can also be persisted and recalled so you can reuse a training javascript classifier save classifier json function err classifier the classifier is saved to the classifier json file to recall from the classifier json saved above javascript natural bayesclassifier load classifier json null function err classifier console log classifier classify long sunw console log classifier classify short sunw a classifier can also be serialized and deserialized like so javascript var classifier new natural bayesclassifier classifier adddocument sell gold sell classifier adddocument buy silver buy serialize var raw json stringify classifier deserialize var restoredclassifier natural bayesclassifier restore json parse raw console log restoredclassifier classify i should sell that note if using the classifier for languages other than english you may need to pass in the stemmer to use in fact you can do this for any stemmer including alternate english stemmers the default is the porterstemmer javascript const porterstemmerru require node modules natural lib natural stemmers porter stemmer ru var classifier new natural bayesclassifier porterstemmerru maximum entropy classifier this module provides a classifier based on maximum entropy modelling the central idea to maximum entropy modelling is to estimate a probability distribution that that has maximum entropy subject to the evidence that is available this means that the distribution follows the data it has seen but does not make any assumptions beyond that the module is not specific to natural language processing or any other application domain there are little requirements with regard to the data structure it can be trained on for training it needs a sample that consists of elements these elements have two parts part a the class of the element part b the context of the element the classifier will once trained return the most probable class for a particular context we start with an explanation of samples and elements you have to create your own specialisation of the element class your element class should implement the generatefeatures method for inferring feature functions from the sample samples and elements elements and contexts are created as follows javascript var myelement require myelementclass var context require context var sample require sample var x new myelementclass x new context 0 a sample is created from an array of elements var sample new sample sample addelement x a class is a string contexts may be as complex as you want as long as it can be serialised a sample can be saved to and loaded from a file javascript sample save sample json function error sample a sample can be read from a file as follows javascript sample load sample json myelementclass function err sample you have to pass the element class to the load method so that the right element objects can be created from the data features and feature sets features are functions that map elements to zero or one features are defined as follows javascript var feature require feature function f x if x b 0 return 1 return 0 var feature new feature f name parameters name is a string for the name of the feature function parameters is an array of strings for the parameters of the feature function the combination of name and parameters should uniquely distinguish features from each other features that are added to a feature set are tested for uniqueness using these properties a feature set is created like this javascript var featureset require featureset var set new featureset set addfeature f f 0 in most cases you will generate feature functions using closures for instance when you generate feature functions in a loop that iterates through an array javascript var featureset require featureset var feature require feature var listoftags nn det prep adj var featureset new featureset listoftags foreach function tag function istag x if x b data tag tag return 1 return 0 featureset addfeature new feature f f tag in this example you create feature functions that each have a different value for tag in their closure setting up and training the classifier a classifier needs the following parameter classes an array of classes strings features an array of feature functions sample a sample of elements for training the classifier a classifier can be created as follows javascript var classifier require classifier var classifier new classifier classes featureset sample and it starts training with javascript var maxiterations 100 var minimprovement 01 var p classifier train maxiterations minimprovement training is finished when either maxiterations is reached or the improvement in likelihood of the sample becomes smaller than minimprovement it returns a probability distribution that can be stored and retrieved for later usage javascript classifier save classifier json function err c if err console log err else continue using the classifier classifier load classifier json function err c if err console log err else use the classifier the training algorithm is based on generalised iterative scaling applying the classifier the classifier can be used to classify contexts in two ways to get the probabilities for all classes javascript var classifications classifier getclassifications context classifications foreach function classplusprobability console log class classplusprobability label has score classplusprobability value this returns a map from classes to probabilities to get the highest scoring class javascript var class classifier classify context console log class simple example of maximum entropy modelling a test is added to the spec folder based on simple elements that have contexts that are either 0 or 1 and classes are x and y javascript a x b data 0 in the se element class that inherits from element the method generatefeatures is implemented it creates a feature function that tests for context 0 after setting up your own element class the classifier can be created and trained application to pos tagging a more elaborate example of maximum entropy modelling is provided for part of speech tagging the following steps are taken to create a classifier and apply it to a test set a new element class pos element is created that has a word window and a tag window around the word to be tagged from the brown corpus a sample is generated consisting of pos elements feature functions are generated from the sample a classifier is created and trained the classifier is applied to a test set results are compared to a simple lexicon based tagger references adwait ratnaparkhi maximum entropy models for natural language ambiguity resolution university of pennsylvania 1998 url http repository upenn edu cgi viewcontent cgi article 1061 context ircs reports darroch j n ratcliff d 1972 generalized iterative scaling for log linear models the annals of mathematical statistics institute of mathematical statistics 43 5 1470–1480 sentiment analysis this is a simple sentiment analysis algorithm based on a vocabulary that assigns polarity to words the algorithm calculates the sentiment of a piece of text by summing the polarity of each word and normalizing with the length of the sentence if a negation occurs the result is made negative it is used as follows javascript var analyzer require natural sentimentanalyzer var stemmer require natural porterstemmer var analyzer new analyzer english stemmer afinn getsentiment expects an array of strings console log analyzer getsentiment i like cherries 0 6666666666666666 the constructor has three parameters language see below for supported languages stemmer to increase the coverage of the sentiment analyzer a stemmer may be provided may be null vocabulary sets the type of vocabulary afinn senticon or pattern are valid values currently the following languages are supported with type of vocabulary and availability of negations in alphabetic order language afinn senticon pattern negations basque x catalan x dutch x x english x x x x french x galician x italian x spanish x x x more languages can be added by adding vocabularies and extending the map languagefiles in sentimentanalyzer js in the tools folder below lib natural sentiment some tools are provided for transforming vocabularies in senticon and pattern format into a json format acknowledgements and references thanks to domingo martín mancera for providing the basis for this sentiment analyzer in his repo lorca afinn is a list of english words rated for valence with an integer between minus five negative and plus five positive the words have been manually labeled by finn årup nielsen in 2009 2011 scientific reference can be found here we used afinn 165 which is available as nodejs module the senticon vocabulary is based on work by fermin l cruz and others cruz fermín l josé a troyano beatriz pontes f javier ortega building layered multilingual sentiment lexicons at synset and lemma levels expert systems with applications 2014 the pattern vocabularies are from the pattern project of the clips research center of university of antwerpen these have a pddl license phonetics phonetic matching sounds like matching can be done with the soundex metaphone or doublemetaphone algorithms javascript var natural require natural var metaphone natural metaphone var soundex natural soundex var worda phonetics var wordb fonetix to test the two words to see if they sound alike javascript if metaphone compare worda wordb console log they sound alike the raw phonetics are obtained with process javascript console log metaphone process phonetics a maximum code length can be supplied javascript console log metaphone process phonetics 3 doublemetaphone deals with two encodings returned in an array this feature is experimental and subject to change javascript var natural require natural var dm natural doublemetaphone var encodings dm process matrix console log encodings 0 console log encodings 1 attaching will patch string with useful methods javascript metaphone attach soundslike is essentially a shortcut to metaphone compare javascript if worda soundslike wordb console log they sound alike the raw phonetics are obtained with phonetics javascript console log phonetics phonetics full text strings can be tokenized into arrays of phonetics much like how tokenization to arrays works for stemmers javascript console log phonetics rock tokenizeandphoneticize same module operations applied with soundex javascript if soundex compare worda wordb console log they sound alike the same string patches apply with soundex javascript soundex attach if worda soundslike wordb console log they sound alike console log phonetics phonetics inflectors nouns nouns can be pluralized singularized with a nouninflector javascript var natural require natural var nouninflector new natural nouninflector to pluralize a word outputs radii javascript console log nouninflector pluralize radius to singularize a word outputs beer javascript console log nouninflector singularize beers like many of the other features string can be patched to perform the operations directly the noun suffix on the methods is necessary as verbs will be supported in the future javascript nouninflector attach console log radius pluralizenoun console log beers singularizenoun numbers numbers can be counted with a countinflector javascript var countinflector natural countinflector outputs 1st javascript console log countinflector nth 1 outputs 111th javascript console log countinflector nth 111 present tense verbs present tense verbs can be pluralized singularized with a presentverbinflector this feature is still experimental as of 0 0 42 so use with caution and please provide feedback javascript var verbinflector new natural presentverbinflector outputs becomes javascript console log verbinflector singularize become outputs become javascript console log verbinflector pluralize becomes like many other natural modules attach can be used to patch strings with handy methods javascript verbinflector attach console log walk singularizepresentverb console log walks pluralizepresentverb n grams n grams can be obtained for either arrays or strings which will be tokenized for you javascript var ngrams natural ngrams bigrams javascript console log ngrams bigrams some words here console log ngrams bigrams some words here both of the above output some words words here trigrams javascript console log ngrams trigrams some other words here console log ngrams trigrams some other words here both of the above output some other words other words here arbitrary n grams javascript console log ngrams ngrams some other words here for you 4 console log ngrams ngrams some other words here for you 4 the above outputs some other words here other words here for words here for you padding n grams can also be returned with left or right padding by passing a start and or end symbol to the bigrams trigrams or ngrams javascript console log ngrams ngrams some other words here for you 4 start end the above will output start start start some start start some other start some other words some other words here other words here for words here for you here for you end for you end end you end end end for only end symbols pass null for the start symbol for instance javascript console log ngrams ngrams some other words here for you 4 null end will output some other words here other words here for words here for you here for you end for you end end you end end end ngramszh for chinese like languages you can use ngramszh to do a n gram and all apis are the same javascript var ngramszh natural ngramszh console log ngramszh bigrams 中文测试 console log ngramszh bigrams 中 文 测 试 console log ngramszh trigrams 中文测试 console log ngramszh trigrams 中 文 测 试 console log ngramszh ngrams 一个中文测试 4 console log ngramszh ngrams 一 个 中 文 测 试 4 tf idf term frequency–inverse document frequency tf idf is implemented to determine how important a word or words is to a document relative to a corpus the following formulas are used for calculating tf and idf tf t d is a so called raw count so just the count of the term in the document idf t d uses the following formula 1 ln n 1 n t where n is the number of documents and n t the number of documents in which the term appears the 1 in the denominator is for handling the possibility that n t is 0 the following example will add four documents to a corpus and determine the weight of the word node and then the weight of the word ruby in each document javascript var natural require natural var tfidf natural tfidf var tfidf new tfidf tfidf adddocument this document is about node tfidf adddocument this document is about ruby tfidf adddocument this document is about ruby and node tfidf adddocument this document is about node it has node examples console log node tfidf tfidfs node function i measure console log document i is measure console log ruby tfidf tfidfs ruby function i measure console log document i is measure the above outputs node document 0 is 1 document 1 is 0 document 2 is 1 document 3 is 2 ruby document 0 is 0 document 1 is 1 2876820724517808 document 2 is 1 2876820724517808 document 3 is 0 this approach can also be applied to individual documents the following example measures the term node in the first and second documents javascript console log tfidf tfidf node 0 console log tfidf tfidf node 1 a tfidf instance can also load documents from files on disk javascript var tfidf new tfidf tfidf addfilesync data files one txt tfidf addfilesync data files two txt multiple terms can be measured as well with their weights being added into a single measure value the following example determines that the last document is the most relevant to the words node and ruby javascript var natural require natural var tfidf natural tfidf var tfidf new tfidf tfidf adddocument this document is about node tfidf adddocument this document is about ruby tfidf adddocument this document is about ruby and node tfidf tfidfs node ruby function i measure console log document i is measure the above outputs document 0 is 1 document 1 is 1 document 2 is 2 the examples above all use strings which causes natural to automatically tokenize the input if you wish to perform your own tokenization or other kinds of processing you can do so then pass in the resultant arrays later this approach allows you to bypass naturals default preprocessing javascript var natural require natural var tfidf natural tfidf var tfidf new tfidf tfidf adddocument document about node tfidf adddocument document about ruby tfidf adddocument document about ruby node tfidf adddocument document about node node examples tfidf tfidfs node ruby function i measure console log document i is measure its possible to retrieve a list of all terms in a document sorted by their importance javascript tfidf listterms 0 document index foreach function item console log item term item tfidf a tfidf instance can also be serialized and deserialized for save and recall javascript var tfidf new tfidf tfidf adddocument document one un tfidf adddocument document two deux var s json stringify tfidf save s to disk database or otherwise assuming you pulled s back out of storage var tfidf new tfidf json parse s tries tries are a very efficient data structure used for prefix based searches natural comes packaged with a basic trie implementation which can support match collection along a path existence search and prefix search building the trie you need to add words to build up the dictionary of the trie this is an example of basic trie set up javascript var natural require natural var trie natural trie var trie new trie add one string at a time trie addstring test or add many strings trie addstrings string1 string2 string3 searching contains the most basic operation on a trie is to see if a search string is marked as a word in the trie javascript console log trie contains test true console log trie contains asdf false find prefix the find prefix search will find the longest prefix that is identified as a word in the trie it will also return the remaining portion of the string which it was not able to match javascript console log trie findprefix tester test er console log trie findprefix string4 null 4 console log trie findprefix string3 string3 all prefixes on path this search will return all prefix matches along the search string path javascript trie addstring tes trie addstring est console log trie findmatchesonpath tester tes test all keys with prefix this search will return all of the words in the trie with the given prefix or if not found javascript console log trie keyswithprefix string string1 string2 string3 case sensitivity by default the trie is case sensitive you can use it in case in sensitive mode by passing false to the trie constructor javascript trie contains test false var citrie new trie false citrie addstring test citrie contains test true in the case of the searches which return strings all strings returned will be in lower case if you are in case in sensitive mode edgeweighteddigraph edgeweighteddigraph represents a digraph you can add an edge get the number vertexes edges get all edges and use tostring to print the digraph initialize a digraph javascript var edgeweighteddigraph natural edgeweighteddigraph var digraph new edgeweighteddigraph digraph add 5 4 0 35 digraph add 5 1 0 32 digraph add 1 3 0 29 digraph add 6 2 0 40 digraph add 3 6 0 52 digraph add 6 4 0 93 the api used is add from to weight get the number of vertexes javascript console log digraph v you will get 7 get the number of edges javascript console log digraph e you will get 6 shortestpathtree shortestpathtree represents a data type for solving the single source shortest paths problem in edge weighted directed acyclic graphs dags the edge weights can be positive negative or zero there are three apis getdistto vertex haspathto vertex pathto vertex javascript var shortestpathtree natural shortestpathtree var spt new shortestpathtree digraph 5 digraph is an instance of edgeweighteddigraph the second param is the start vertex of dag getdistto vertex will return the dist to vertex javascript console log spt getdistto 4 the output will be 0 35 pathto vertex will return the shortest path javascript console log spt pathto 4 output will be javascript 5 4 longestpathtree longestpathtree represents a data type for solving the single source longest paths problem in edge weighted directed acyclic graphs dags the edge weights can be positive negative or zero there are three apis same as shortestpathtree getdistto vertex haspathto vertex pathto vertex javascript var longestpathtree natural longestpathtree var lpt new longestpathtree digraph 5 digraph is an instance of edgeweighteddigraph the second param is the start vertex of dag getdistto vertex will return the dist to vertex javascript console log lpt getdistto 4 the output will be 2 06 pathto vertex will return the longest path javascript console log lpt pathto 4 output will be javascript 5 1 3 6 4 wordnet one of the newest and most experimental features in natural is wordnet integration heres an example of using natural to look up definitions of the word node to use the wordnet module first install the wordnet database files using wordnet db npm install wordnet db keep in mind that the wordnet integration is to be considered experimental at this point and not production ready the api is also subject to change for an implementation with vastly increased performance as well as a command line interface see wordpos heres an example of looking up definitions for the word node javascript var wordnet new natural wordnet wordnet lookup node function results results foreach function result console log console log result synsetoffset console log result pos console log result lemma console log result synonyms console log result pos console log result gloss given a synset offset and a part of speech a definition can be looked up directly javascript var wordnet new natural wordnet wordnet get 4424418 n function result console log console log result lemma console log result pos console log result gloss console log result synonyms if you have manually downloaded the wordnet database files you can pass the folder to the constructor javascript var wordnet new natural wordnet my wordnet dict as of v0 1 11 wordnet data files are no longer automatically downloaded princeton university about wordnet wordnet princeton university 2010 http wordnet princeton edu spellcheck a probabilistic spellchecker based on http norvig com spell correct html this is best constructed with an array of tokens from a corpus but a simple list of words from a dictionary will work javascript var corpus something soothing var spellcheck new natural spellcheck corpus it uses the trie datastructure for fast boolean lookup of a word javascript spellcheck iscorrect cat false it suggests corrections sorted by probability in descending order that are up to a maximum edit distance away from the input word according to norvig a max distance of 1 will cover 80 to 95 of spelling mistakes after a distance of 2 it becomes very slow javascript spellcheck getcorrections soemthing 1 something spellcheck getcorrections soemthing 2 something soothing pos tagger this is a part of speech tagger based on eric brills transformational algorithm transformation rules are specified in external files usage javascript var natural require natural var path require path var base folder path join path dirname require resolve natural brill pos tagger var rulesfilename base folder data english tr from posjs txt var lexiconfilename base folder data english lexicon from posjs json var defaultcategory n var lexicon new natural lexicon lexiconfilename defaultcategory var rules new natural ruleset rulesfilename var tagger new natural brillpostagger lexicon rules var sentence i see the man with the telescope console log tagger tag sentence this outputs the following sentence taggedwords token i tag nn token see tag vb token the tag dt token man tag nn token with tag in token the tag dt token telescope tag nn lexicon the lexicon is either a json file that has the following structure javascript word1 cat1 word2 cat2 cat3 or a text file word1 cat1 cat2 word2 cat3 words may have multiple categories in the lexicon file the tagger uses only the first category specified specifying transformation rules transformation rules are specified as follows old cat new cat predicate parameter this means that if the category of the current position is old cat and the predicate is true the category is replaced by new cat the predicate may use the parameter in different ways sometimes the parameter is used for specifying the outcome of the predicate nn cd current word is number yes this means that if the outcome of predicate current word is number is yes the category is replaced by cd the parameter can also be used to check the category of a word in the sentence vbd nn prev tag dt here the category of the previous word must be dt for the rule to be applied algorithm the tagger applies transformation rules that may change the category of words the input sentence is a sentence object with tagged words the tagged sentence is processed from left to right at each step all rules are applied once rules are applied in the order in which they are specified algorithm javascript brill pos tagger prototype applyrules function sentence for var i 0 size sentence taggedwords length i size i this ruleset getrules foreach function rule rule apply sentence i return sentence the output is a sentence object just like the input sentence adding a predicate predicates are defined in module lib ruletemplates js in that file predicate names are mapped to metadata for generaring transformation rules the following properties must be supplied name of the predicate a function that evaluates the predicate should return a boolean a window i j that defines the span of the predicate in the sentence relative to the current position the number of parameter the predicate needs 0 1 or 2 if relevant a function for parameter 1 that returns its possible values at the current position in the sentence for generating rules in training if relevant a function for parameter 2 that returns its possible values at the current position in the sentence for training a typical entry for a rule templates looks like this javascript next tag maps to the predicate function function next tag is minimum required window before or after current position to be a relevant predicate window 0 1 the number of parameters the predicate takes nrparameters 1 function that returns relevant values for parameter 1 parameter1values nexttagparametervalues a predicate function accepts a sentence object the current position in the sentence that should be tagged and the outcome s of the predicate an example of a predicate that checks the category of the current word javascript function next tag is sentence i parameter if i sentence taggedwords length 1 return sentence taggedwords i 1 1 parameter else return false a values function for a parameter returns an array all possible parameter values given a location in a tagged sentence javascript function nexttagparametervalues sentence i if i sentence length 1 return sentence i 1 tag else return training the trainer allows to learn a new set of transformation rules from a corpus it takes as input a tagged corpus and a set of rule templates the algorithm generates positive rules rules that apply at some location in the corpus from the templates and iteratively extends and optimises the rule set first a corpus should be loaded currently the format of brown corpus is supported then a lexicon can be created from the corpus the lexicon is needed for tagging the sentences before the learning algorithm is applied javascript var natural require natural var text fs readfilesync browncorpusfile utf8 var corpus new natural corpus text 1 var lexicon corpus buildlexicon the next step is to create a set of rule templates from which the learning algorithm can generate transformation rules rule templates are defined in predicatemapping js javascript var natural require natural var templatenames next tag next word is cap prev 1 or 2 or 3 tag var templates templatenames map function name return new natural ruletemplate name using lexicon and rule templates we can now start the trainer as follows javascript var natural require natural var tester require natural brillpostrainer var trainer new trainer optional threshold var ruleset trainer train corpus templates lexicon a threshold value can be passed to constructor transformation rules with a score below the threshold are removed after training the train method returns a set of transformation rules that can be used to create a pos tagger as usual also you can output the rule set in the right format for later usage javascript console log ruleset prettyprint testing now we can apply the lexicon and rule set to a test set javascript var tester new natural brillpostester var tagger new natural brillpostagger lexicon ruleset var scores tester test corpora 1 tagger the test method returns an array of two percentages first percentage is the ratio of right tags after tagging with the lexicon second percentage is the ratio of right tags after applying the transformation rules javascript console log test score lexicon scores 0 console log test score after applying rules scores 1 acknowledgements and references part of speech tagger by percy wegmann https code google com p jspos node js version of jspos https github com neopunisher pos js a simple rule based part of speech tagger eric brill published in proceeding anlc 92 proceedings of the third conference on applied natural language processing pages 152 155 http dl acm org citation cfm id 974526 exploring the statistical derivation of transformational rule sequences for part of speech tagging lance a ramshaw and mitchell p marcus http acl arc comp nus edu sg archives acl arc 090501d4 data pdf anthology pdf w w94 w94 0111 pdf brown corpus https en wikipedia org wiki brown corpus development when developing please write unit tests make sure your unit tests pass the current configuration of the unit tests requires the following environment variable to be set export node path license copyright c 2011 2012 chris umbel rob ellis russell mull permission is hereby granted free of charge to any person obtaining a copy of this software and associated documentation files the software to deal in the software without restriction including without limitation the rights to use copy modify merge publish distribute sublicense and or sell copies of the software and to permit persons to whom the software is furnished to do so subject to the following conditions the above copyright notice and this permission notice shall be included in all copies or substantial portions of the software the software is provided as is without warranty of any kind express or implied including but not limited to the warranties of merchantability fitness for a particular purpose and noninfringement in no event shall the authors or copyright holders be liable for any claim damages or other liability whether in an action of contract tort or otherwise arising from out of or in connection with the software or the use or other dealings in the software wordnet license this license is available as the file license in any downloaded version of wordnet wordnet 3 0 license download wordnet release 3 0 this software and database is being provided to you the licensee by princeton university under the following license by obtaining using and or copying this software and database you agree that you have read understood and will comply with these terms and conditions permission to use copy modify and distribute this software and database and its documentation for any purpose and without fee or royalty is hereby granted provided that you agree to comply with the following copyright notice and statements including the disclaimer and that the same appear on all copies of the software database and documentation including modifications that you make for internal use or for distribution wordnet 3 0 copyright 2006 by princeton university all rights reserved this software and database is provided as is and princeton university makes no representations or warranties express or implied by way of example but not limitation princeton university makes no representations or warranties of merchant ability or fitness for any particular purpose or that the use of the licensed software database or documentation will not infringe any third party patents copyrights trademarks or other rights the name of princeton university or princeton may not be used in advertising or publicity pertaining to distribution of the software and or database title to copyright in this software database and any associated documentation shall at all times remain with princeton university and licensee agrees to preserve same