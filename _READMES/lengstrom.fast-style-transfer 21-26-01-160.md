fast style transfer in tensorflow add styles from famous paintings to any photo in a fraction of a second you can even style videos it takes 100ms on a 2015 titan x to style the mit stata center 1024Ã—680 like udnie by francis picabia our implementation is based off of a combination of gatys a neural algorithm of artistic style johnsons perceptual losses for real time style transfer and super resolution and ulyanovs instance normalization license copyright c 2016 logan engstrom contact me for commercial use or rather any use that is not academic research email engstrom at my universitys domain dot edu free for research use as long as proper attribution is given and this copyright notice is retained video stylization here we transformed every frame in a video then combined the results click to go to the full demo on youtube the style here is udnie as above see how to generate these videos here image stylization we added styles from various paintings to a photo of chicago click on thumbnails to see full applied style images implementation details our implementation uses tensorflow to train a fast style transfer network we use roughly the same transformation network as described in johnson except that batch normalization is replaced with ulyanovs instance normalization and the scaling offset of the output tanh layer is slightly different we use a loss function close to the one described in gatys using vgg19 instead of vgg16 and typically using shallower layers than in johnsons implementation e g we use relu1 1 rather than relu1 2 empirically this results in larger scale style features in transformations documentation training style transfer networks use style py to train a new style transfer network run python style py to view all the possible parameters training takes 4 6 hours on a maxwell titan x more detailed documentation here before you run this you should run setup sh example usage python style py style path to style img jpg \ checkpoint dir checkpoint path \ test path to test img jpg \ test dir path to test dir \ content weight 1 5e1 \ checkpoint iterations 1000 \ batch size 20 evaluating style transfer networks use evaluate py to evaluate a style transfer network run python evaluate py to view all the possible parameters evaluation takes 100 ms per frame when batch size is 1 on a maxwell titan x more detailed documentation here takes several seconds per frame on a cpu models for evaluation are located here example usage python evaluate py checkpoint path to style model ckpt \ in path dir of test imgs \ out path dir for results stylizing video use transform video py to transfer style into a video run python transform video py to view all the possible parameters requires ffmpeg more detailed documentation here example usage python transform video py in path path to input vid mp4 \ checkpoint path to style model ckpt \ out path out video mp4 \ device gpu 0 \ batch size 4 requirements you will need the following to run the above tensorflow 0 11 0 python 2 7 9 pillow 3 4 2 scipy 0 18 1 numpy 1 11 2 if you want to train and dont want to wait for 4 months a decent gpu all the required nvidia software to run tf on a gpu cuda etc ffmpeg 3 1 3 if you want to stylize video citation misc engstrom2016faststyletransfer author logan engstrom title fast style transfer year 2016 howpublished \url https github com lengstrom fast style transfer note commit xxxxxxx attributions thanks this project could not have happened without the advice and gpu access given by anish athalye the project also borrowed some code from anishs neural style some readme docs formatting was borrowed from justin johnsons fast neural style the image of the stata center at the very beginning of the readme was taken by juan paulo related work michael ramos ported this network to use coreml on ios