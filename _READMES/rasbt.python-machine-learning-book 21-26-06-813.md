python machine learning book code repository important note 09 21 2017 this github repository contains the code examples of the 1st edition of python machine learning book if you are looking for the code examples of the 2nd edition please refer to this repository instead what you can expect are 400 pages rich in useful material just about everything you need to know to get started with machine learning from theory to the actual code that you can directly put into action this is not yet just another this is how scikit learn works book i aim to explain all the underlying concepts tell you everything you need to know in terms of best practices and caveats and we will put those concepts into action mainly using numpy scikit learn and theano you are not sure if this book is for you please checkout the excerpts from the foreword and preface or take a look at the faq section for further information 1st edition published september 23rd 2015 paperback 454 pages publisher packt publishing language english isbn 10 1783555130 isbn 13 978 1783555130 kindle asin b00ysilnl0 german isbn 13 978 3958454224 japanese isbn 13 978 4844380603 italian isbn 13 978 8850333974 chinese traditional isbn 13 978 9864341405 chinese mainland isbn 13 978 7111558804 korean isbn 13 979 1187497035 russian isbn 13 978 5970604090 table of contents and code notebooks simply click on the ipynb nbviewer links next to the chapter headlines to view the code examples currently the internal document links are only supported by the nbviewer version please note that these are just the code examples accompanying the book which i uploaded for your convenience be aware that these notebooks may not be useful without the formulae and descriptive text excerpts from the foreword and preface instructions for setting up python and the jupiter notebook machine learning giving computers the ability to learn from data dir ipynb nbviewer training machine learning algorithms for classification dir ipynb nbviewer a tour of machine learning classifiers using scikit learn dir ipynb nbviewer building good training sets – data pre processing dir ipynb nbviewer compressing data via dimensionality reduction dir ipynb nbviewer learning best practices for model evaluation and hyperparameter optimization dir ipynb nbviewer combining different models for ensemble learning dir ipynb nbviewer applying machine learning to sentiment analysis dir ipynb nbviewer embedding a machine learning model into a web application dir ipynb nbviewer predicting continuous target variables with regression analysis dir ipynb nbviewer working with unlabeled data – clustering analysis dir ipynb nbviewer training artificial neural networks for image recognition dir ipynb nbviewer parallelizing neural network training via theano dir ipynb nbviewer equation reference pdf tex slides for teaching a big thanks to dmitriy dligach for sharing his slides from his machine learning course that is currently offered at loyola university chicago https github com dmitriydligach pymlslides additional math and numpy resources some readers were asking about math and numpy primers since they were not included due to length limitations however i recently put together such resources for another book but i made these chapters freely available online in hope that they also serve as helpful background material for this book algebra basics pdf epub a calculus and differentiation primer pdf epub introduction to numpy pdf epub code notebook citing this book you are very welcome to re use the code snippets or other contents from this book in scientific publications and other works in this case i would appreciate citations to the original source bibtex book raschka2015python author raschka sebastian title python machine learning publisher packt publishing year 2015 address birmingham uk isbn 1783555130 mla raschka sebastian python machine learning birmingham uk packt publishing 2015 print feedback reviews short review snippets sebastian raschkas new book python machine learning has just been released i got a chance to read a review copy and its just as i expected really great its well organized super easy to follow and it not only offers a good foundation for smart non experts practitioners will get some ideas and learn new tricks here as well – lon riesberg at data elixir superb job thus far for me it seems to have hit the right balance of theory and practice…math and code – brian thomas ive read virtually every machine learning title based around scikit learn and this is hands down the best one out there – jason wolosonovich the best book ive seen to come out of packt publishing this is a very well written introduction to machine learning with python as others have noted a perfect mixture of theory and application – josh d a book with a blend of qualities that is hard to come by combines the needed mathematics to control the theory with the applied coding in python also great to see it doesnt waste paper in giving a primer on python as many other books do just to appeal to the greater audience you can tell its been written by knowledgeable writers and not just diy geeks – amazon customer sebastian raschka created an amazing machine learning tutorial which combines theory with practice the book explains machine learning from a theoretical perspective and has tons of coded examples to show how you would actually use the machine learning technique it can be read by a beginner or advanced programmer william p ross 7 must read python books longer reviews if you need help to decide whether this book is for you check out some of the longer reviews linked below if you wrote a review please let me know and id be happy to add it to the list python machine learning review by patrick hill at the chartered institute for it book review python machine learning by sebastian raschka by alex turner at whatpixel links ebook and paperback at amazon com amazon co uk amazon de ebook and paperback from packt the publisher at other book stores google books oreilly safari barnes noble apple ibooks social platforms goodreads translations italian translation via apogeo german translation via mitp verlag japanese translation via impress top gear chinese translation traditional chinese chinese translation simple chinese korean translation via kyobo polish translation via helion literature references further reading resources errata bonus notebooks not in the book logistic regression implementation dir ipynb nbviewer a basic pipeline and grid search setup dir ipynb nbviewer an extended nested cross validation example dir ipynb nbviewer a simple barebones flask webapp template view directory download as zip file reading handwritten digits from mnist into numpy arrays github ipynb nbviewer scikit learn model persistence using json github ipynb nbviewer multinomial logistic regression softmax regression github ipynb nbviewer related content not in the book model evaluation model selection and algorithm selection in machine learning part i model evaluation model selection and algorithm selection in machine learning part ii model evaluation model selection and algorithm selection in machine learning part iii scipy 2016 we had such a great time at scipy 2016 in austin it was a real pleasure to meet and chat with so many readers of my book thanks so much for all the nice words and feedback and in case you missed it andreas mueller and i gave an introduction to machine learning with scikit learn if you are interested the video recordings of part i and part ii are now online pydata chicago 2016 i attempted the rather challenging task of introducing scikit learn machine learning in just 90 minutes at pydata chicago 2016 the slides and tutorial material are available at learning scikit learn an introduction to machine learning in python note i have set up a separate library mlxtend containing additional implementations of machine learning and general data science algorithms i also added implementations from this book for example the decision region plot the artificial neural network and sequential feature selection algorithms with additional functionality translations dear readers first of all i want to thank all of you for the great support i am really happy about all the great feedback you sent me so far and i am glad that the book has been so useful to a broad audience over the last couple of months i received hundreds of emails and i tried to answer as many as possible in the available time i have to make them useful to other readers as well i collected many of my answers in the faq section below in addition some of you asked me about a platform for readers to discuss the contents of the book i hope that this would provide an opportunity for you to discuss and share your knowledge with other readers google groups discussion board and i will try my best to answer questions myself if time allows the only thing to do with good advice is to pass it on it is never of any use to oneself — oscar wilde examples and applications by readers once again i have to say big thanks for all the nice feedback about the book ive received many emails from readers who put the concepts and examples from this book out into the real world and make good use of them in their projects in this section i am starting to gather some of these great applications and id be more than happy to add your project to this list just shoot me a quick mail 40 scripts on optical character recognition by richard lyman code experiments by jeremy nation what i learned implementing a classifier from scratch in python by jean nicholas hould faq general questions what are machine learning and data science why do you and other people sometimes implement machine learning algorithms from scratch what learning path discipline in data science i should focus on at what point should one start contributing to open source how important do you think having a mentor is to the learning process where are the best online communities centered around data science machine learning or python how would you explain machine learning to a software engineer how would your curriculum for a machine learning beginner look like what is the definition of data science how do data scientists perform model selection is it different from kaggle questions about the machine learning field how are artificial intelligence and machine learning related what are some real world examples of applications of machine learning in the field what are the different fields of study in data mining what are differences in research nature between the two fields machine learning data mining how do i know if the problem is solvable through machine learning what are the origins of machine learning how was classification as a learning machine developed which machine learning algorithms can be considered as among the best what are the broad categories of classifiers what is the difference between a classifier and a model what is the difference between a parametric learning algorithm and a nonparametric learning algorithm what is the difference between a cost function and a loss function in machine learning questions about ml concepts and statistics cost functions and optimization fitting a model via closed form equations vs gradient descent vs stochastic gradient descent vs mini batch learning what is the difference how do you derive the gradient descent rule for linear regression and adaline regression analysis what is the difference between pearson r and simple linear regression tree models how does the random forest model work how is it different from bagging and boosting in ensemble models what are the disadvantages of using classic decision tree algorithm for a large dataset why are implementations of decision tree algorithms usually binary and what are the advantages of the different impurity metrics why are we growing decision trees via entropy instead of the classification error when can a random forest perform terribly model evaluation what is overfitting how can i avoid overfitting is it always better to have the largest possible number of folds when performing cross validation when training an svm classifier is it better to have a large or small number of support vectors how do i evaluate a model what is the best validation metric for multi class classification what factors should i consider when choosing a predictive model technique what are the best toy datasets to help visualize and understand classifier behavior how do i select svm kernels interlude comparing and computing performance metrics in cross validation imbalanced class problems and 3 different ways to compute the f1 score logistic regression what is softmax regression and how is it related to logistic regression why is logistic regression considered a linear model what is the probabilistic interpretation of regularized logistic regression does regularization in logistic regression always results in better fit and better generalization what is the major difference between naive bayes and logistic regression what exactly is the softmax and the multinomial logistic loss in the context of machine learning what is the relation between loigistic regression and neural networks and when to use which logistic regression why sigmoid function is there an analytical solution to logistic regression similar to the normal equation for linear regression neural networks and deep learning what is the difference between deep learning and usual machine learning can you give a visual explanation for the back propagation algorithm for neural networks why did it take so long for deep networks to be invented what are some good books papers for learning deep learning why are there so many deep learning libraries why do some people hate neural networks deep learning how can i know if deep learning works better for a specific problem than svm or random forest what is wrong when my neural networks error increases how do i debug an artificial neural network algorithm what is the difference between a perceptron adaline and neural network model what is the basic idea behind the dropout technique other algorithms for supervised learning why is nearest neighbor a lazy algorithm unsupervised learning what are some of the issues with clustering semi supervised learning what are the advantages of semi supervised learning over supervised and unsupervised learning ensemble methods is combining classifiers with stacking better than selecting the best one preprocessing feature selection and extraction why do we need to re use training parameters to transform test data what are the different dimensionality reduction methods in machine learning what is the difference between lda and pca for dimensionality reduction when should i apply data normalization standardization does mean centering or feature scaling affect a principal component analysis how do you attack a machine learning problem with a large number of features what are some common approaches for dealing with missing data what is the difference between filter wrapper and embedded methods for feature selection should data preparation pre processing step be considered one part of feature engineering why or why not is a bag of words feature representation for text classification considered as a sparse matrix naive bayes why is the naive bayes classifier naive what is the decision boundary for naive bayes can i use naive bayes classifiers for mixed variable types is it possible to mix different variable types in naive bayes for example binary and continues features other what is euclidean distance in terms of machine learning when should one use median as opposed to the mean or average programming languages and libraries for data science and machine learning is r used extensively today in data science what is the main difference between tensorflow and scikit learn questions about the book can i use paragraphs and images from the book in presentations or my blog how is this different from other machine learning books which version of python was used in the code examples which technologies and libraries are being used which book version format would you recommend why did you choose python for machine learning why do you use so many leading and trailing underscores in the code examples what is the purpose of the return self idioms in your code examples are there any prerequisites and recommended pre readings how can i apply svm to categorical data contact i am happy to answer questions just write me an email or consider asking the question on the google groups email list if you are interested in keeping in touch i have quite a lively twitter stream rasbt all about data science and machine learning i also maintain a blog where i post all of the things i am particularly excited about