cyclegan pytorch project page paper torch implementation for learning an image to image translation i e pix2pix without input output pairs for example unpaired image to image translation using cycle consistent adversarial networks jun yan zhu taesung park phillip isola alexei a efros berkeley ai research lab uc berkeley in arxiv 2017 equal contributions this package includes cyclegan pix2pix as well as other methods like bigan ali and apples paper s u learning the code was written by jun yan zhu and taesung park note please check out pytorch implementation for cyclegan and pix2pix the pytorch version is under active development and can produce results comparable or better than this torch version other implementations tensorflow by harry yang tensorflow by archit rathore tensorflow by van huy tensorflow by xiaowei hu tensorflow simple by zhenliang he tensorlayer by luoxier chainer by yanghua jin minimal pytorch by yunjey mxnet by ldpe2g lasagne keras by tjwei applications monet paintings to photos collection style transfer object transfiguration season transfer photo enhancement narrow depth of field prerequisites linux or osx nvidia gpu cuda cudnn cpu mode and cuda without cudnn may work with minimal modification but untested for mac users you need the linux gnu commands gfind and gwc which can be installed with brew install findutils coreutils getting started installation install torch and dependencies from https github com torch distro install torch packages nngraph class display bash luarocks install nngraph luarocks install class luarocks install https raw githubusercontent com szym display master display scm 0 rockspec clone this repo bash git clone https github com junyanz cyclegan cd cyclegan apply a pre trained model download the test photos taken by alexei efros bash datasets download dataset sh ae photos download the pre trained model style cezanne for cpu model use style cezanne cpu bash pretrained models download model sh style cezanne now lets generate paul c√©zanne style images data root datasets ae photos name style cezanne pretrained model one direction test phase test loadsize 256 finesize 256 resize or crop scale width th test lua the test results will be saved to results style cezanne pretrained latest test index html please refer to model zoo for more pre trained models examples test vangogh style on ae photos sh is an example script that downloads the pretrained van gogh style network and runs it on efross photos train download a dataset e g zebra and horse images from imagenet bash bash datasets download dataset sh horse2zebra train a model bash data root datasets horse2zebra name horse2zebra model th train lua cpu only the same training command without using a gpu or cudnn setting the environment variables gpu 0 cudnn 0 forces cpu only bash data root datasets horse2zebra name horse2zebra model gpu 0 cudnn 0 th train lua optionally start the display server to view results as the model trains see display ui for more details bash th ldisplay start 8000 0 0 0 0 test finally test the model bash data root datasets horse2zebra name horse2zebra model phase test th test lua the test results will be saved to a html file here results horse2zebra model latest test index html model zoo download the pre trained models with the following script the model will be saved to checkpoints model name latest net g t7 bash bash pretrained models download model sh model name orange2apple orange apple and apple2orange trained on imagenet categories apple and orange horse2zebra horse zebra and zebra2horse zebra horse trained on imagenet categories horse and zebra style monet landscape photo monet painting style style vangogh landscape photo van gogh painting style style ukiyoe landscape photo ukiyo e painting style style cezanne landscape photo cezanne painting style trained on paintings and flickr landscape photos monet2photo monet paintings real landscape trained on paintings and flickr landscape photographs cityscapes photo2label street scene label and cityscapes label2photo label street scene trained on the cityscapes dataset map2sat map aerial photo and sat2map aerial photo map trained on google maps iphone2dslr flower iphone photos of flowers dslr photos of flowers trained on flickr photos cpu models can be downloaded using bash bash pretrained models download model sh name cpu where name can be horse2zebra style monet etc you just need to append cpu to the target model training and test details to train a model bash data root path to data name expt name th train lua models are saved to checkpoints expt name can be changed by passing checkpoint dir your dir in train lua see opt train in options lua for additional training options to test the model bash data root path to data name expt name phase test th test lua this will run the model named expt name in both directions on all images in path to data testa and path to data testb result images and a webpage to view them are saved to results expt name can be changed by passing results dir your dir in test lua see opt test in options lua for additional test options please use model one direction test if you only would like to generate outputs of the trained network in only one direction and specify which direction atob or which direction btoa to set the direction datasets download the datasets using the following script some of the datasets are collected by other researchers please cite their papers if you use the data bash bash datasets download dataset sh dataset name facades 400 images from the cmp facades dataset citation cityscapes 2975 images from the cityscapes training set citation maps 1096 training images scraped from google maps horse2zebra 939 horse images and 1177 zebra images downloaded from imagenet using keywords wild horse and zebra apple2orange 996 apple images and 1020 orange images downloaded from imagenet using keywords apple and navel orange summer2winter yosemite 1273 summer yosemite images and 854 winter yosemite images were downloaded using flickr api see more details in our paper monet2photo vangogh2photo ukiyoe2photo cezanne2photo the art images were downloaded from wikiart the real photos are downloaded from flickr using the combination of the tags landscape and landscapephotography the training set size of each class is monet 1074 cezanne 584 van gogh 401 ukiyo e 1433 photographs 6853 iphone2dslr flower both classes of images were downlaoded from flickr the training set size of each class is iphone 1813 dslr 3316 see more details in our paper display ui optionally for displaying images during training and test use the display package install it with luarocks install https raw githubusercontent com szym display master display scm 0 rockspec then start the server with th ldisplay start open this url in your browser http localhost 8000 by default the server listens on localhost pass 0 0 0 0 to allow external connections on any interface bash th ldisplay start 8000 0 0 0 0 then open http hostname port in your browser to load the remote desktop setup training and test data to train cyclegan model on your own datasets you need to create a data folder with two subdirectories traina and trainb that contain images from domain a and b you can test your model on your training set by setting phase train in test lua you can also create subdirectories testa and testb if you have test data you should not expect our method to work on just any random combination of input and output datasets e g cats keyboards from our experiments we find it works better if two datasets share similar visual content for example landscape painting landscape photographs works much better than portrait painting landscape photographs zebras horses achieves compelling results while cats dogs completely fails see the following section for more discussion failure cases our model does not work well when the test image is rather different from the images on which the model is trained as is the case in the figure to the left we trained on horses and zebras without riders but test here one a horse with a rider see additional typical failure cases here on translation tasks that involve color and texture changes like many of those reported above the method often succeeds we have also explored tasks that require geometric changes with little success for example on the task of dog cat transfiguration the learned translation degenerates to making minimal changes to the input we also observe a lingering gap between the results achievable with paired training data and those achieved by our unpaired method in some cases this gap may be very hard or even impossible to close for example our method sometimes permutes the labels for tree and building in the output of the cityscapes photos labels task citation if you use this code for your research please cite our paper inproceedings cyclegan2017 title unpaired image to image translation using cycle consistent adversarial networkss author zhu jun yan and park taesung and isola phillip and efros alexei a booktitle computer vision iccv 2017 ieee international conference on year 2017 related projects pix2pix image to image translation using conditional adversarial nets igan interactive image generation via generative adversarial networks cat paper collection if you love cats and love reading cool graphics vision and learning papers please check out the cat paper collection github webpage acknowledgments code borrows from pix2pix and dcgan the data loader is modified from dcgan and context encoder the generative network is adopted from neural style with instance normalization