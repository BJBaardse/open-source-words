gpuimage brad larson http www sunsetlakesoftware com bradlarson contact sunsetlakesoftware com overview the gpuimage framework is a bsd licensed ios library that lets you apply gpu accelerated filters and other effects to images live camera video and movies in comparison to core image part of ios 5 0 gpuimage allows you to write your own custom filters supports deployment to ios 4 0 and has a simpler interface however it currently lacks some of the more advanced features of core image such as facial detection for massively parallel operations like processing images or live video frames gpus have some significant performance advantages over cpus on an iphone 4 a simple image filter can be over 100 times faster to perform on the gpu than an equivalent cpu based filter however running custom filters on the gpu requires a lot of code to set up and maintain an opengl es 2 0 rendering target for these filters i created a sample project to do this http www sunsetlakesoftware com 2010 10 22 gpu accelerated video processing mac and ios and found that there was a lot of boilerplate code i had to write in its creation therefore i put together this framework that encapsulates a lot of the common tasks youll encounter when processing images and video and made it so that you dont need to care about the opengl es 2 0 underpinnings this framework compares favorably to core image when handling video taking only 2 5 ms on an iphone 4 to upload a frame from the camera apply a gamma filter and display versus 106 ms for the same operation using core image cpu based processing takes 460 ms making gpuimage 40x faster than core image for this operation on this hardware and 184x faster than cpu bound processing on an iphone 4s gpuimage is only 4x faster than core image for this case and 102x faster than cpu bound processing however for more complex operations like gaussian blurs at larger radii core image currently outpaces gpuimage license bsd style with the full license available with the framework in license txt technical requirements opengl es 2 0 applications using this will not run on the original iphone iphone 3g and 1st and 2nd generation ipod touches ios 4 1 as a deployment target 4 0 didnt have some extensions needed for movie reading ios 4 3 is needed as a deployment target if you wish to show live video previews when taking a still photo ios 5 0 sdk to build devices must have a camera to use camera related functionality obviously the framework uses automatic reference counting arc but should support projects using both arc and manual reference counting if added as a subproject as explained below for manual reference counting applications targeting ios 4 x youll need add fobjc arc to the other linker flags for your application project general architecture gpuimage uses opengl es 2 0 shaders to perform image and video manipulation much faster than could be done in cpu bound routines however it hides the complexity of interacting with the opengl es api in a simplified objective c interface this interface lets you define input sources for images and video attach filters in a chain and send the resulting processed image or video to the screen to a uiimage or to a movie on disk images or frames of video are uploaded from source objects which are subclasses of gpuimageoutput these include gpuimagevideocamera for live video from an ios camera gpuimagestillcamera for taking photos with the camera gpuimagepicture for still images and gpuimagemovie for movies source objects upload still image frames to opengl es as textures then hand those textures off to the next objects in the processing chain filters and other subsequent elements in the chain conform to the gpuimageinput protocol which lets them take in the supplied or processed texture from the previous link in the chain and do something with it objects one step further down the chain are considered targets and processing can be branched by adding multiple targets to a single output or filter for example an application that takes in live video from the camera converts that video to a sepia tone then displays the video onscreen would set up a chain looking something like the following gpuimagevideocamera gpuimagesepiafilter gpuimageview adding the static library to your ios project note if you want to use this in a swift project you need to use the steps in the adding this as a framework section instead of the following swift needs modules for third party code once you have the latest source code for the framework its fairly straightforward to add it to your application start by dragging the gpuimage xcodeproj file into your applications xcode project to embed the framework in your project next go to your applications target and add gpuimage as a target dependency finally youll want to drag the libgpuimage a library from the gpuimage frameworks products folder to the link binary with libraries build phase in your applications target gpuimage needs a few other frameworks to be linked into your application so youll need to add the following as linked libraries in your application target coremedia corevideo opengles avfoundation quartzcore youll also need to find the framework headers so within your projects build settings set the header search paths to the relative path from your application to the framework subdirectory within the gpuimage source directory make this header search path recursive to use the gpuimage classes within your application simply include the core framework header using the following import gpuimage h as a note if you run into the error unknown class gpuimageview in interface builder or the like when trying to build an interface with interface builder you may need to add objc to your other linker flags in your projects build settings also if you need to deploy this to ios 4 x it appears that the current version of xcode 4 3 requires that you weak link the core video framework in your final application or you see crashes with the message symbol not found cvopenglestexturecachecreate when you create an archive for upload to the app store or for ad hoc distribution to do this go to your projects build phases tab expand the link binary with libraries group and find corevideo framework in the list change the setting for it in the far right of the list from required to optional additionally this is an arc enabled framework so if you want to use this within a manual reference counted application targeting ios 4 x youll need to add fobjc arc to your other linker flags as well building a static library at the command line if you dont want to include the project as a dependency in your applications xcode project you can build a universal static library for the ios simulator or device to do this run build sh at the command line the resulting library and header files will be located at build release iphone you may also change the version of the ios sdk by changing the iossdk ver variable in build sh all available versions can be found using xcodebuild showsdks adding this as a framework module to your mac or ios project xcode 6 and ios 8 support the use of full frameworks as does the mac which simplifies the process of adding this to your application to add this to your application i recommend dragging the xcodeproj project file into your applications project as you would in the static library target for your application go to its target build settings and choose the build phases tab under the target dependencies grouping add gpuimageframework on ios not gpuimage which builds the static library or gpuimage on the mac under the link binary with libraries section add gpuimage framework this should cause gpuimage to build as a framework under xcode 6 this will also build as a module which will allow you to use this in swift projects when set up as above you should just need to use import gpuimage to pull it in you then need to add a new copy files build phase set the destination to frameworks and add the gpuimage framework build product to that this will allow the framework to be bundled with your application otherwise youll see cryptic dyld library not loaded rpath gpuimage framework gpuimage errors on execution documentation documentation is generated from header comments using appledoc to build the documentation switch to the documentation scheme in xcode you should ensure that appledoc path a user defined build setting points to an appledoc binary available on github or through homebrew it will also build and install a docset file which you can view with your favorite documentation tool performing common tasks filtering live video to filter live video from an ios devices camera you can use code like the following gpuimagevideocamera videocamera gpuimagevideocamera alloc initwithsessionpreset avcapturesessionpreset640x480 cameraposition avcapturedevicepositionback videocamera outputimageorientation uiinterfaceorientationportrait gpuimagefilter customfilter gpuimagefilter alloc initwithfragmentshaderfromfile customshader gpuimageview filteredvideoview gpuimageview alloc initwithframe cgrectmake 0 0 0 0 viewwidth viewheight add the view somewhere so its visible videocamera addtarget customfilter customfilter addtarget filteredvideoview videocamera startcameracapture this sets up a video source coming from the ios devices back facing camera using a preset that tries to capture at 640x480 this video is captured with the interface being in portrait mode where the landscape left mounted camera needs to have its video frames rotated before display a custom filter using code from the file customshader fsh is then set as the target for the video frames from the camera these filtered video frames are finally displayed onscreen with the help of a uiview subclass that can present the filtered opengl es texture that results from this pipeline the fill mode of the gpuimageview can be altered by setting its fillmode property so that if the aspect ratio of the source video is different from that of the view the video will either be stretched centered with black bars or zoomed to fill for blending filters and others that take in more than one image you can create multiple outputs and add a single filter as a target for both of these outputs the order with which the outputs are added as targets will affect the order in which the input images are blended or otherwise processed also if you wish to enable microphone audio capture for recording to a movie youll need to set the audioencodingtarget of the camera to be your movie writer like for the following videocamera audioencodingtarget moviewriter capturing and filtering a still photo to capture and filter still photos you can use a process similar to the one for filtering video instead of a gpuimagevideocamera you use a gpuimagestillcamera stillcamera gpuimagestillcamera alloc init stillcamera outputimageorientation uiinterfaceorientationportrait filter gpuimagegammafilter alloc init stillcamera addtarget filter gpuimageview filterview gpuimageview self view filter addtarget filterview stillcamera startcameracapture this will give you a live filtered feed of the still cameras preview video note that this preview video is only provided on ios 4 3 and higher so you may need to set that as your deployment target if you wish to have this functionality once you want to capture a photo you use a callback block like the following stillcamera capturephotoprocesseduptofilter filter withcompletionhandler uiimage processedimage nserror error nsdata dataforjpegfile uiimagejpegrepresentation processedimage 0 8 nsarray paths nssearchpathfordirectoriesindomains nsdocumentdirectory nsuserdomainmask yes nsstring documentsdirectory paths objectatindex 0 nserror error2 nil if dataforjpegfile writetofile documentsdirectory stringbyappendingpathcomponent filteredphoto jpg options nsatomicwrite error error2 return the above code captures a full size photo processed by the same filter chain used in the preview view and saves that photo to disk as a jpeg in the applications documents directory note that the framework currently cant handle images larger than 2048 pixels wide or high on older devices those before the iphone 4s ipad 2 or retina ipad due to texture size limitations this means that the iphone 4 whose camera outputs still photos larger than this wont be able to capture photos like this a tiling mechanism is being implemented to work around this all other devices should be able to capture and filter photos using this method processing a still image there are a couple of ways to process a still image and create a result the first way you can do this is by creating a still image source object and manually creating a filter chain uiimage inputimage uiimage imagenamed lambeau jpg gpuimagepicture stillimagesource gpuimagepicture alloc initwithimage inputimage gpuimagesepiafilter stillimagefilter gpuimagesepiafilter alloc init stillimagesource addtarget stillimagefilter stillimagefilter usenextframeforimagecapture stillimagesource processimage uiimage currentfilteredvideoframe stillimagefilter imagefromcurrentframebuffer note that for a manual capture of an image from a filter you need to set usenextframeforimagecapture in order to tell the filter that youll be needing to capture from it later by default gpuimage reuses framebuffers within filters to conserve memory so if you need to hold on to a filters framebuffer for manual image capture you need to let it know ahead of time for single filters that you wish to apply to an image you can simply do the following gpuimagesepiafilter stillimagefilter2 gpuimagesepiafilter alloc init uiimage quickfilteredimage stillimagefilter2 imagebyfilteringimage inputimage writing a custom filter one significant advantage of this framework over core image on ios as of ios 5 0 is the ability to write your own custom image and video processing filters these filters are supplied as opengl es 2 0 fragment shaders written in the c like opengl shading language a custom filter is initialized with code like gpuimagefilter customfilter gpuimagefilter alloc initwithfragmentshaderfromfile customshader where the extension used for the fragment shader is fsh additionally you can use the initwithfragmentshaderfromstring initializer to provide the fragment shader as a string if you would not like to ship your fragment shaders in your application bundle fragment shaders perform their calculations for each pixel to be rendered at that filter stage they do this using the opengl shading language glsl a c like language with additions specific to 2 d and 3 d graphics an example of a fragment shader is the following sepia tone filter varying highp vec2 texturecoordinate uniform sampler2d inputimagetexture void main lowp vec4 texturecolor texture2d inputimagetexture texturecoordinate lowp vec4 outputcolor outputcolor r texturecolor r 0 393 texturecolor g 0 769 texturecolor b 0 189 outputcolor g texturecolor r 0 349 texturecolor g 0 686 texturecolor b 0 168 outputcolor b texturecolor r 0 272 texturecolor g 0 534 texturecolor b 0 131 outputcolor a 1 0 gl fragcolor outputcolor for an image filter to be usable within the gpuimage framework the first two lines that take in the texturecoordinate varying for the current coordinate within the texture normalized to 1 0 and the inputimagetexture uniform for the actual input image frame texture are required the remainder of the shader grabs the color of the pixel at this location in the passed in texture manipulates it in such a way as to produce a sepia tone and writes that pixel color out to be used in the next stage of the processing pipeline one thing to note when adding fragment shaders to your xcode project is that xcode thinks they are source code files to work around this youll need to manually move your shader from the compile sources build phase to the copy bundle resources one in order to get the shader to be included in your application bundle filtering and re encoding a movie movies can be loaded into the framework via the gpuimagemovie class filtered and then written out using a gpuimagemoviewriter gpuimagemoviewriter is also fast enough to record video in realtime from an iphone 4s camera at 640x480 so a direct filtered video source can be fed into it currently gpuimagemoviewriter is fast enough to record live 720p video at up to 20 fps on the iphone 4 and both 720p and 1080p video at 30 fps on the iphone 4s as well as on the new ipad the following is an example of how you would load a sample movie pass it through a pixellation filter then record the result to disk as a 480 x 640 h 264 movie moviefile gpuimagemovie alloc initwithurl sampleurl pixellatefilter gpuimagepixellatefilter alloc init moviefile addtarget pixellatefilter nsstring pathtomovie nshomedirectory stringbyappendingpathcomponent documents movie m4v unlink pathtomovie utf8string nsurl movieurl nsurl fileurlwithpath pathtomovie moviewriter gpuimagemoviewriter alloc initwithmovieurl movieurl size cgsizemake 480 0 640 0 pixellatefilter addtarget moviewriter moviewriter shouldpassthroughaudio yes moviefile audioencodingtarget moviewriter moviefile enablesynchronizedencodingusingmoviewriter moviewriter moviewriter startrecording moviefile startprocessing once recording is finished you need to remove the movie recorder from the filter chain and close off the recording using code like the following pixellatefilter removetarget moviewriter moviewriter finishrecording a movie wont be usable until it has been finished off so if this is interrupted before this point the recording will be lost interacting with opengl es gpuimage can both export and import textures from opengl es through the use of its gpuimagetextureoutput and gpuimagetextureinput classes respectively this lets you record a movie from an opengl es scene that is rendered to a framebuffer object with a bound texture or filter video or images and then feed them into opengl es as a texture to be displayed in the scene the one caution with this approach is that the textures used in these processes must be shared between gpuimages opengl es context and any other context via a share group or something similar built in filters there are currently 125 built in filters divided into the following categories color adjustments gpuimagebrightnessfilter adjusts the brightness of the image brightness the adjusted brightness 1 0 1 0 with 0 0 as the default gpuimageexposurefilter adjusts the exposure of the image exposure the adjusted exposure 10 0 10 0 with 0 0 as the default gpuimagecontrastfilter adjusts the contrast of the image contrast the adjusted contrast 0 0 4 0 with 1 0 as the default gpuimagesaturationfilter adjusts the saturation of an image saturation the degree of saturation or desaturation to apply to the image 0 0 2 0 with 1 0 as the default gpuimagegammafilter adjusts the gamma of an image gamma the gamma adjustment to apply 0 0 3 0 with 1 0 as the default gpuimagelevelsfilter photoshop like levels adjustment the min max minout and maxout parameters are floats in the range 0 1 if you have parameters from photoshop in the range 0 255 you must first convert them to be 0 1 the gamma mid parameter is a float 0 this matches the value from photoshop if you want to apply levels to rgb as well as individual channels you need to use this filter twice first for the individual channels and then for all channels gpuimagecolormatrixfilter transforms the colors of an image by applying a matrix to them colormatrix a 4x4 matrix used to transform each color in an image intensity the degree to which the new transformed color replaces the original color for each pixel gpuimagergbfilter adjusts the individual rgb channels of an image red normalized values by which each color channel is multiplied the range is from 0 0 up with 1 0 as the default green blue gpuimagehuefilter adjusts the hue of an image hue the hue angle in degrees 90 degrees by default gpuimagevibrancefilter adjusts the vibrance of an image vibrance the vibrance adjustment to apply using 0 0 as the default and a suggested min max of around 1 2 and 1 2 respectively gpuimagewhitebalancefilter adjusts the white balance of an image temperature the temperature to adjust the image by in ºk a value of 4000 is very cool and 7000 very warm the default value is 5000 note that the scale between 4000 and 5000 is nearly as visually significant as that between 5000 and 7000 tint the tint to adjust the image by a value of 200 is very green and 200 is very pink the default value is 0 gpuimagetonecurvefilter adjusts the colors of an image based on spline curves for each color channel redcontrolpoints greencontrolpoints bluecontrolpoints rgbcompositecontrolpoints the tone curve takes in a series of control points that define the spline curve for each color component or for all three in the composite these are stored as nsvalue wrapped cgpoints in an nsarray with normalized x and y coordinates from 0 1 the defaults are 0 0 0 5 0 5 1 1 gpuimagehighlightshadowfilter adjusts the shadows and highlights of an image shadows increase to lighten shadows from 0 0 to 1 0 with 0 0 as the default highlights decrease to darken highlights from 1 0 to 0 0 with 1 0 as the default gpuimagehighlightshadowtintfilter allows you to tint the shadows and highlights of an image independently using a color and intensity shadowtintcolor shadow tint rgb color gpuvector4 default 1 0f 0 0f 0 0f 1 0f red highlighttintcolor highlight tint rgb color gpuvector4 default 0 0f 0 0f 1 0f 1 0f blue shadowtintintensity shadow tint intensity from 0 0 to 1 0 default 0 0 highlighttintintensity highlight tint intensity from 0 0 to 1 0 with 0 0 as the default gpuimagelookupfilter uses an rgb color lookup image to remap the colors in an image first use your favourite photo editing application to apply a filter to lookup png from gpuimage framework resources for this to work properly each pixel color must not depend on other pixels e g blur will not work if you need a more complex filter you can create as many lookup tables as required once ready use your new lookup png file as a second input for gpuimagelookupfilter gpuimageamatorkafilter a photo filter based on a photoshop action by amatorka http amatorka deviantart com art amatorka action 2 121069631 if you want to use this effect you have to add lookup amatorka png from the gpuimage resources folder to your application bundle gpuimagemissetikatefilter a photo filter based on a photoshop action by miss etikate http miss etikate deviantart com art photoshop action 15 120151961 if you want to use this effect you have to add lookup miss etikate png from the gpuimage resources folder to your application bundle gpuimagesoftelegancefilter another lookup based color remapping filter if you want to use this effect you have to add lookup soft elegance 1 png and lookup soft elegance 2 png from the gpuimage resources folder to your application bundle gpuimageskintonefilter a skin tone adjustment filter that affects a unique range of light skin tone colors and adjusts the pink green or pink orange range accordingly default values are targetted at fair caucasian skin but can be adjusted as required skintoneadjust amount to adjust skin tone default 0 0 suggested min max 0 3 and 0 3 respectively skinhue skin hue to be detected default 0 05 fair caucasian to reddish skin skinhuethreshold amount of variance in skin hue default 40 0 maxhueshift maximum amount of hue shifting allowed default 0 25 maxsaturationshift maximum amount of saturation to be shifted when using orange default 0 4 upperskintonecolor gpuimageskintoneuppercolorgreen or gpuimageskintoneuppercolororange gpuimagecolorinvertfilter inverts the colors of an image gpuimagegrayscalefilter converts an image to grayscale a slightly faster implementation of the saturation filter without the ability to vary the color contribution gpuimagemonochromefilter converts the image to a single color version based on the luminance of each pixel intensity the degree to which the specific color replaces the normal image color 0 0 1 0 with 1 0 as the default color the color to use as the basis for the effect with 0 6 0 45 0 3 1 0 as the default gpuimagefalsecolorfilter uses the luminance of the image to mix between two user specified colors firstcolor the first and second colors specify what colors replace the dark and light areas of the image respectively the defaults are 0 0 0 0 0 5 amd 1 0 0 0 0 0 secondcolor gpuimagehazefilter used to add or remove haze similar to a uv filter distance strength of the color applied default 0 values between 3 and 3 are best slope amount of color change default 0 values between 3 and 3 are best gpuimagesepiafilter simple sepia tone filter intensity the degree to which the sepia tone replaces the normal image color 0 0 1 0 with 1 0 as the default gpuimageopacityfilter adjusts the alpha channel of the incoming image opacity the value to multiply the incoming alpha channel for each pixel by 0 0 1 0 with 1 0 as the default gpuimagesolidcolorgenerator this outputs a generated image with a solid color you need to define the image size using forceprocessingatsize color the color in a four component format that is used to fill the image gpuimageluminancethresholdfilter pixels with a luminance above the threshold will appear white and those below will be black threshold the luminance threshold from 0 0 to 1 0 with a default of 0 5 gpuimageadaptivethresholdfilter determines the local luminance around a pixel then turns the pixel black if it is below that local luminance and white if above this can be useful for picking out text under varying lighting conditions blurradiusinpixels a multiplier for the background averaging blur radius in pixels with a default of 4 gpuimageaverageluminancethresholdfilter this applies a thresholding operation where the threshold is continually adjusted based on the average luminance of the scene thresholdmultiplier this is a factor that the average luminance will be multiplied by in order to arrive at the final threshold to use by default this is 1 0 gpuimagehistogramfilter this analyzes the incoming image and creates an output histogram with the frequency at which each color value occurs the output of this filter is a 3 pixel high 256 pixel wide image with the center vertical pixels containing pixels that correspond to the frequency at which various color values occurred each color value occupies one of the 256 width positions from 0 on the left to 255 on the right this histogram can be generated for individual color channels kgpuimagehistogramred kgpuimagehistogramgreen kgpuimagehistogramblue the luminance of the image kgpuimagehistogramluminance or for all three color channels at once kgpuimagehistogramrgb downsamplingfactor rather than sampling every pixel this dictates what fraction of the image is sampled by default this is 16 with a minimum of 1 this is needed to keep from saturating the histogram which can only record 256 pixels for each color value before it becomes overloaded gpuimagehistogramgenerator this is a special filter in that its primarily intended to work with the gpuimagehistogramfilter it generates an output representation of the color histograms generated by gpuimagehistogramfilter but it could be repurposed to display other kinds of values it takes in an image and looks at the center vertical pixels it then plots the numerical values of the rgb components in separate colored graphs in an output texture you may need to force a size for this filter in order to make its output visible gpuimageaveragecolor this processes an input image and determines the average color of the scene by averaging the rgba components for each pixel in the image a reduction process is used to progressively downsample the source image on the gpu followed by a short averaging calculation on the cpu the output from this filter is meaningless but you need to set the coloraverageprocessingfinishedblock property to a block that takes in four color components and a frame time and does something with them gpuimageluminosity like the gpuimageaveragecolor this reduces an image to its average luminosity you need to set the luminosityprocessingfinishedblock to handle the output of this filter which just returns a luminosity value and a frame time gpuimagechromakeyfilter for a given color in the image sets the alpha channel to 0 this is similar to the gpuimagechromakeyblendfilter only instead of blending in a second image for a matching color this doesnt take in a second image and just turns a given color transparent thresholdsensitivity how close a color match needs to exist to the target color to be replaced default of 0 4 smoothing how smoothly to blend for the color match default of 0 1 image processing gpuimagetransformfilter this applies an arbitrary 2 d or 3 d transformation to an image affinetransform this takes in a cgaffinetransform to adjust an image in 2 d transform3d this takes in a catransform3d to manipulate an image in 3 d ignoreaspectratio by default the aspect ratio of the transformed image is maintained but this can be set to yes to make the transformation independent of aspect ratio gpuimagecropfilter this crops an image to a specific region then passes only that region on to the next stage in the filter cropregion a rectangular area to crop out of the image normalized to coordinates from 0 0 1 0 the 0 0 0 0 position is in the upper left of the image gpuimagelanczosresamplingfilter this lets you up or downsample an image using lanczos resampling which results in noticeably better quality than the standard linear or trilinear interpolation simply use forceprocessingatsize to set the target output resolution for the filter and the image will be resampled for that new size gpuimagesharpenfilter sharpens the image sharpness the sharpness adjustment to apply 4 0 4 0 with 0 0 as the default gpuimageunsharpmaskfilter applies an unsharp mask blurradiusinpixels the blur radius of the underlying gaussian blur the default is 4 0 intensity the strength of the sharpening from 0 0 on up with a default of 1 0 gpuimagegaussianblurfilter a hardware optimized variable radius gaussian blur texelspacingmultiplier a multiplier for the spacing between texels ranging from 0 0 on up with a default of 1 0 adjusting this may slightly increase the blur strength but will introduce artifacts in the result highly recommend using other parameters first before touching this one blurradiusinpixels a radius in pixels to use for the blur with a default of 2 0 this adjusts the sigma variable in the gaussian distribution function blurradiusasfractionofimagewidth blurradiusasfractionofimageheight setting these properties will allow the blur radius to scale with the size of the image blurpasses the number of times to sequentially blur the incoming image the more passes the slower the filter gpuimageboxblurfilter a hardware optimized variable radius box blur texelspacingmultiplier a multiplier for the spacing between texels ranging from 0 0 on up with a default of 1 0 adjusting this may slightly increase the blur strength but will introduce artifacts in the result highly recommend using other parameters first before touching this one blurradiusinpixels a radius in pixels to use for the blur with a default of 2 0 this adjusts the sigma variable in the gaussian distribution function blurradiusasfractionofimagewidth blurradiusasfractionofimageheight setting these properties will allow the blur radius to scale with the size of the image blurpasses the number of times to sequentially blur the incoming image the more passes the slower the filter gpuimagesinglecomponentgaussianblurfilter a modification of the gpuimagegaussianblurfilter that operates only on the red component texelspacingmultiplier a multiplier for the spacing between texels ranging from 0 0 on up with a default of 1 0 adjusting this may slightly increase the blur strength but will introduce artifacts in the result highly recommend using other parameters first before touching this one blurradiusinpixels a radius in pixels to use for the blur with a default of 2 0 this adjusts the sigma variable in the gaussian distribution function blurradiusasfractionofimagewidth blurradiusasfractionofimageheight setting these properties will allow the blur radius to scale with the size of the image blurpasses the number of times to sequentially blur the incoming image the more passes the slower the filter gpuimagegaussianselectiveblurfilter a gaussian blur that preserves focus within a circular region blurradiusinpixels a radius in pixels to use for the blur with a default of 5 0 this adjusts the sigma variable in the gaussian distribution function excludecircleradius the radius of the circular area being excluded from the blur excludecirclepoint the center of the circular area being excluded from the blur excludeblursize the size of the area between the blurred portion and the clear circle aspectratio the aspect ratio of the image used to adjust the circularity of the in focus region by default this matches the image aspect ratio but you can override this value gpuimagegaussianblurpositionfilter the inverse of the gpuimagegaussianselectiveblurfilter applying the blur only within a certain circle blursize a multiplier for the size of the blur ranging from 0 0 on up with a default of 1 0 blurcenter center for the blur defaults to 0 5 0 5 blurradius radius for the blur defaults to 1 0 gpuimageiosblurfilter an attempt to replicate the background blur used on ios 7 in places like the control center blurradiusinpixels a radius in pixels to use for the blur with a default of 12 0 this adjusts the sigma variable in the gaussian distribution function saturation saturation ranges from 0 0 fully desaturated to 2 0 max saturation with 0 8 as the normal level downsampling the degree to which to downsample then upsample the incoming image to minimize computations within the gaussian blur with a default of 4 0 gpuimagemedianfilter takes the median value of the three color components over a 3x3 area gpuimagebilateralfilter a bilateral blur which tries to blur similar color values while preserving sharp edges texelspacingmultiplier a multiplier for the spacing between texel reads ranging from 0 0 on up with a default of 4 0 distancenormalizationfactor a normalization factor for the distance between central color and sample color with a default of 8 0 gpuimagetiltshiftfilter a simulated tilt shift lens effect blurradiusinpixels the radius of the underlying blur in pixels this is 7 0 by default topfocuslevel the normalized location of the top of the in focus area in the image this value should be lower than bottomfocuslevel default 0 4 bottomfocuslevel the normalized location of the bottom of the in focus area in the image this value should be higher than topfocuslevel default 0 6 focusfalloffrate the rate at which the image gets blurry away from the in focus region default 0 2 gpuimage3x3convolutionfilter runs a 3x3 convolution kernel against the image convolutionkernel the convolution kernel is a 3x3 matrix of values to apply to the pixel and its 8 surrounding pixels the matrix is specified in row major order with the top left pixel being one one and the bottom right three three if the values in the matrix dont add up to 1 0 the image could be brightened or darkened gpuimagesobeledgedetectionfilter sobel edge detection with edges highlighted in white texelwidth texelheight these parameters affect the visibility of the detected edges edgestrength adjusts the dynamic range of the filter higher values lead to stronger edges but can saturate the intensity colorspace default is 1 0 gpuimageprewittedgedetectionfilter prewitt edge detection with edges highlighted in white texelwidth texelheight these parameters affect the visibility of the detected edges edgestrength adjusts the dynamic range of the filter higher values lead to stronger edges but can saturate the intensity colorspace default is 1 0 gpuimagethresholdedgedetectionfilter performs sobel edge detection but applies a threshold instead of giving gradual strength values texelwidth texelheight these parameters affect the visibility of the detected edges edgestrength adjusts the dynamic range of the filter higher values lead to stronger edges but can saturate the intensity colorspace default is 1 0 threshold any edge above this threshold will be black and anything below white ranges from 0 0 to 1 0 with 0 8 as the default gpuimagecannyedgedetectionfilter this uses the full canny process to highlight one pixel wide edges texelwidth texelheight these parameters affect the visibility of the detected edges blurradiusinpixels the underlying blur radius for the gaussian blur default is 2 0 blurtexelspacingmultiplier the underlying blur texel spacing multiplier default is 1 0 upperthreshold any edge with a gradient magnitude above this threshold will pass and show up in the final result default is 0 4 lowerthreshold any edge with a gradient magnitude below this threshold will fail and be removed from the final result default is 0 1 gpuimageharriscornerdetectionfilter runs the harris corner detection algorithm on an input image and produces an image with those corner points as white pixels and everything else black the cornersdetectedblock can be set and you will be provided with a list of corners in normalized 0 1 x y coordinates within that callback for whatever additional operations you want to perform blurradiusinpixels the radius of the underlying gaussian blur the default is 2 0 sensitivity an internal scaling factor applied to adjust the dynamic range of the cornerness maps generated in the filter the default is 5 0 threshold the threshold at which a point is detected as a corner this can vary significantly based on the size lighting conditions and ios device camera type so it might take a little experimentation to get right for your cases default is 0 20 gpuimagenoblecornerdetectionfilter runs the noble variant on the harris corner detector it behaves as described above for the harris detector blurradiusinpixels the radius of the underlying gaussian blur the default is 2 0 sensitivity an internal scaling factor applied to adjust the dynamic range of the cornerness maps generated in the filter the default is 5 0 threshold the threshold at which a point is detected as a corner this can vary significantly based on the size lighting conditions and ios device camera type so it might take a little experimentation to get right for your cases default is 0 2 gpuimageshitomasicornerdetectionfilter runs the shi tomasi feature detector it behaves as described above for the harris detector blurradiusinpixels the radius of the underlying gaussian blur the default is 2 0 sensitivity an internal scaling factor applied to adjust the dynamic range of the cornerness maps generated in the filter the default is 1 5 threshold the threshold at which a point is detected as a corner this can vary significantly based on the size lighting conditions and ios device camera type so it might take a little experimentation to get right for your cases default is 0 2 gpuimagenonmaximumsuppressionfilter currently used only as part of the harris corner detection filter this will sample a 1 pixel box around each pixel and determine if the center pixels red channel is the maximum in that area if it is it stays if not it is set to 0 for all color components gpuimagexyderivativefilter an internal component within the harris corner detection filter this calculates the squared difference between the pixels to the left and right of this one the squared difference of the pixels above and below this one and the product of those two differences gpuimagecrosshairgenerator this draws a series of crosshairs on an image most often used for identifying machine vision features it does not take in a standard image like other filters but a series of points in its rendercrosshairsfromarray count method which does the actual drawing you will need to force this filter to render at the particular output size you need crosshairwidth the width in pixels of the crosshairs to be drawn onscreen gpuimagedilationfilter this performs an image dilation operation where the maximum intensity of the red channel in a rectangular neighborhood is used for the intensity of this pixel the radius of the rectangular area to sample over is specified on initialization with a range of 1 4 pixels this is intended for use with grayscale images and it expands bright regions gpuimagergbdilationfilter this is the same as the gpuimagedilationfilter except that this acts on all color channels not just the red channel gpuimageerosionfilter this performs an image erosion operation where the minimum intensity of the red channel in a rectangular neighborhood is used for the intensity of this pixel the radius of the rectangular area to sample over is specified on initialization with a range of 1 4 pixels this is intended for use with grayscale images and it expands dark regions gpuimagergberosionfilter this is the same as the gpuimageerosionfilter except that this acts on all color channels not just the red channel gpuimageopeningfilter this performs an erosion on the red channel of an image followed by a dilation of the same radius the radius is set on initialization with a range of 1 4 pixels this filters out smaller bright regions gpuimagergbopeningfilter this is the same as the gpuimageopeningfilter except that this acts on all color channels not just the red channel gpuimageclosingfilter this performs a dilation on the red channel of an image followed by an erosion of the same radius the radius is set on initialization with a range of 1 4 pixels this filters out smaller dark regions gpuimagergbclosingfilter this is the same as the gpuimageclosingfilter except that this acts on all color channels not just the red channel gpuimagelocalbinarypatternfilter this performs a comparison of intensity of the red channel of the 8 surrounding pixels and that of the central one encoding the comparison results in a bit string that becomes this pixel intensity the least significant bit is the top right comparison going counterclockwise to end at the right comparison as the most significant bit gpuimagelowpassfilter this applies a low pass filter to incoming video frames this basically accumulates a weighted rolling average of previous frames with the current ones as they come in this can be used to denoise video add motion blur or be used to create a high pass filter filterstrength this controls the degree by which the previous accumulated frames are blended with the current one this ranges from 0 0 to 1 0 with a default of 0 5 gpuimagehighpassfilter this applies a high pass filter to incoming video frames this is the inverse of the low pass filter showing the difference between the current frame and the weighted rolling average of previous ones this is most useful for motion detection filterstrength this controls the degree by which the previous accumulated frames are blended and then subtracted from the current one this ranges from 0 0 to 1 0 with a default of 0 5 gpuimagemotiondetector this is a motion detector based on a high pass filter you set the motiondetectionblock and on every incoming frame it will give you the centroid of any detected movement in the scene in normalized x y coordinates as well as an intensity of motion for the scene lowpassfilterstrength this controls the strength of the low pass filter used behind the scenes to establish the baseline that incoming frames are compared with this ranges from 0 0 to 1 0 with a default of 0 5 gpuimagehoughtransformlinedetector detects lines in the image using a hough transform into parallel coordinate space this approach is based entirely on the pc lines process developed by the graph fit research group at the brno university of technology and described in their publications m dubská j havel and a herout real time detection of lines using parallel coordinates and opengl proceedings of sccg 2011 bratislava sk p 7 http medusa fit vutbr cz public data papers 2011 sccg dubska real time line detection using pc and opengl pdf and m dubská j havel and a herout pclines — line detection using parallel coordinates 2011 ieee conference on computer vision and pattern recognition cvpr p 1489 1494 http medusa fit vutbr cz public data papers 2011 cvpr dubska pclines pdf edgethreshold a threshold value for which a point is detected as belonging to an edge for determining lines default is 0 9 linedetectionthreshold a threshold value for which a local maximum is detected as belonging to a line in parallel coordinate space default is 0 20 linesdetectedblock this block is called on the detection of lines usually on every processed frame a c array containing normalized slopes and intercepts in m b pairs y mx b is passed in along with a count of the number of lines detected and the current timestamp of the video frame gpuimagelinegenerator a helper class that generates lines which can overlay the scene the color of these lines can be adjusted using setlinecolorred green blue linewidth the width of the lines in pixels with a default of 1 0 gpuimagemotionblurfilter applies a directional motion blur to an image blursize a multiplier for the blur size ranging from 0 0 on up with a default of 1 0 blurangle the angular direction of the blur in degrees 0 degrees by default gpuimagezoomblurfilter applies a directional motion blur to an image blursize a multiplier for the blur size ranging from 0 0 on up with a default of 1 0 blurcenter the normalized center of the blur 0 5 0 5 by default blending modes gpuimagechromakeyblendfilter selectively replaces a color in the first image with the second image thresholdsensitivity how close a color match needs to exist to the target color to be replaced default of 0 4 smoothing how smoothly to blend for the color match default of 0 1 gpuimagedissolveblendfilter applies a dissolve blend of two images mix the degree with which the second image overrides the first 0 0 1 0 with 0 5 as the default gpuimagemultiplyblendfilter applies a multiply blend of two images gpuimageaddblendfilter applies an additive blend of two images gpuimagesubtractblendfilter applies a subtractive blend of two images gpuimagedivideblendfilter applies a division blend of two images gpuimageoverlayblendfilter applies an overlay blend of two images gpuimagedarkenblendfilter blends two images by taking the minimum value of each color component between the images gpuimagelightenblendfilter blends two images by taking the maximum value of each color component between the images gpuimagecolorburnblendfilter applies a color burn blend of two images gpuimagecolordodgeblendfilter applies a color dodge blend of two images gpuimagescreenblendfilter applies a screen blend of two images gpuimageexclusionblendfilter applies an exclusion blend of two images gpuimagedifferenceblendfilter applies a difference blend of two images gpuimagehardlightblendfilter applies a hard light blend of two images gpuimagesoftlightblendfilter applies a soft light blend of two images gpuimagealphablendfilter blends the second image over the first based on the seconds alpha channel mix the degree with which the second image overrides the first 0 0 1 0 with 1 0 as the default gpuimagesourceoverblendfilter applies a source over blend of two images gpuimagecolorburnblendfilter applies a color burn blend of two images gpuimagecolordodgeblendfilter applies a color dodge blend of two images gpuimagenormalblendfilter applies a normal blend of two images gpuimagecolorblendfilter applies a color blend of two images gpuimagehueblendfilter applies a hue blend of two images gpuimagesaturationblendfilter applies a saturation blend of two images gpuimageluminosityblendfilter applies a luminosity blend of two images gpuimagelinearburnblendfilter applies a linear burn blend of two images gpuimagepoissonblendfilter applies a poisson blend of two images mix mix ranges from 0 0 only image 1 to 1 0 only image 2 gradients with 1 0 as the normal level numiterations the number of times to propagate the gradients crank this up to 100 or even 1000 if you want to get anywhere near convergence yes this will be slow gpuimagemaskfilter masks one image using another visual effects gpuimagepixellatefilter applies a pixellation effect on an image or video fractionalwidthofapixel how large the pixels are as a fraction of the width and height of the image 0 0 1 0 default 0 05 gpuimagepolarpixellatefilter applies a pixellation effect on an image or video based on polar coordinates instead of cartesian ones center the center about which to apply the pixellation defaulting to 0 5 0 5 pixelsize the fractional pixel size split into width and height components the default is 0 05 0 05 gpuimagepolkadotfilter breaks an image up into colored dots within a regular grid fractionalwidthofapixel how large the dots are as a fraction of the width and height of the image 0 0 1 0 default 0 05 dotscaling what fraction of each grid space is taken up by a dot from 0 0 to 1 0 with a default of 0 9 gpuimagehalftonefilter applies a halftone effect to an image like news print fractionalwidthofapixel how large the halftone dots are as a fraction of the width and height of the image 0 0 1 0 default 0 05 gpuimagecrosshatchfilter this converts an image into a black and white crosshatch pattern crosshatchspacing the fractional width of the image to use as the spacing for the crosshatch the default is 0 03 linewidth a relative width for the crosshatch lines the default is 0 003 gpuimagesketchfilter converts video to look like a sketch this is just the sobel edge detection filter with the colors inverted texelwidth texelheight these parameters affect the visibility of the detected edges edgestrength adjusts the dynamic range of the filter higher values lead to stronger edges but can saturate the intensity colorspace default is 1 0 gpuimagethresholdsketchfilter same as the sketch filter only the edges are thresholded instead of being grayscale texelwidth texelheight these parameters affect the visibility of the detected edges edgestrength adjusts the dynamic range of the filter higher values lead to stronger edges but can saturate the intensity colorspace default is 1 0 threshold any edge above this threshold will be black and anything below white ranges from 0 0 to 1 0 with 0 8 as the default gpuimagetoonfilter this uses sobel edge detection to place a black border around objects and then it quantizes the colors present in the image to give a cartoon like quality to the image texelwidth texelheight these parameters affect the visibility of the detected edges threshold the sensitivity of the edge detection with lower values being more sensitive ranges from 0 0 to 1 0 with 0 2 as the default quantizationlevels the number of color levels to represent in the final image default is 10 0 gpuimagesmoothtoonfilter this uses a similar process as the gpuimagetoonfilter only it precedes the toon effect with a gaussian blur to smooth out noise texelwidth texelheight these parameters affect the visibility of the detected edges blurradiusinpixels the radius of the underlying gaussian blur the default is 2 0 threshold the sensitivity of the edge detection with lower values being more sensitive ranges from 0 0 to 1 0 with 0 2 as the default quantizationlevels the number of color levels to represent in the final image default is 10 0 gpuimageembossfilter applies an embossing effect on the image intensity the strength of the embossing from 0 0 to 4 0 with 1 0 as the normal level gpuimageposterizefilter this reduces the color dynamic range into the number of steps specified leading to a cartoon like simple shading of the image colorlevels the number of color levels to reduce the image space to this ranges from 1 to 256 with a default of 10 gpuimageswirlfilter creates a swirl distortion on the image radius the radius from the center to apply the distortion with a default of 0 5 center the center of the image in normalized coordinates from 0 1 0 about which to twist with a default of 0 5 0 5 angle the amount of twist to apply to the image with a default of 1 0 gpuimagebulgedistortionfilter creates a bulge distortion on the image radius the radius from the center to apply the distortion with a default of 0 25 center the center of the image in normalized coordinates from 0 1 0 about which to distort with a default of 0 5 0 5 scale the amount of distortion to apply from 1 0 to 1 0 with a default of 0 5 gpuimagepinchdistortionfilter creates a pinch distortion of the image radius the radius from the center to apply the distortion with a default of 1 0 center the center of the image in normalized coordinates from 0 1 0 about which to distort with a default of 0 5 0 5 scale the amount of distortion to apply from 2 0 to 2 0 with a default of 1 0 gpuimagestretchdistortionfilter creates a stretch distortion of the image center the center of the image in normalized coordinates from 0 1 0 about which to distort with a default of 0 5 0 5 gpuimagesphererefractionfilter simulates the refraction through a glass sphere center the center about which to apply the distortion with a default of 0 5 0 5 radius the radius of the distortion ranging from 0 0 to 1 0 with a default of 0 25 refractiveindex the index of refraction for the sphere with a default of 0 71 gpuimageglassspherefilter same as the gpuimagesphererefractionfilter only the image is not inverted and theres a little bit of frosting at the edges of the glass center the center about which to apply the distortion with a default of 0 5 0 5 radius the radius of the distortion ranging from 0 0 to 1 0 with a default of 0 25 refractiveindex the index of refraction for the sphere with a default of 0 71 gpuimagevignettefilter performs a vignetting effect fading out the image at the edges vignettecenter the center for the vignette in tex coords cgpoint with a default of 0 5 0 5 vignettecolor the color to use for the vignette gpuvector3 with a default of black vignettestart the normalized distance from the center where the vignette effect starts with a default of 0 5 vignetteend the normalized distance from the center where the vignette effect ends with a default of 0 75 gpuimagekuwaharafilter kuwahara image abstraction drawn from the work of kyprianidis et al in their publication anisotropic kuwahara filtering on the gpu within the gpu pro collection this produces an oil painting like image but it is extremely computationally expensive so it can take seconds to render a frame on an ipad 2 this might be best used for still images radius in integer specifying the number of pixels out from the center pixel to test when applying the filter with a default of 4 a higher value creates a more abstracted image but at the cost of much greater processing time gpuimagekuwahararadius3filter a modified version of the kuwahara filter optimized to work over just a radius of three pixels gpuimageperlinnoisefilter generates an image full of perlin noise colorstart colorfinish the color range for the noise being generated scale the scaling of the noise being generated gpuimagecgacolorspacefilter simulates the colorspace of a cga monitor gpuimagemosaicfilter this filter takes an input tileset the tiles must ascend in luminance it looks at the input image and replaces each display tile with an input tile according to the luminance of that tile the idea was to replicate the ascii video filters seen in other apps but the tileset can be anything inputtilesize numtiles displaytilesize coloron gpuimagejfavoronoifilter generates a voronoi map for use in a later stage sizeinpixels size of the individual elements gpuimagevoronoiconsumerfilter takes in the voronoi map and uses that to filter an incoming image sizeinpixels size of the individual elements you can also easily write your own custom filters using the c like opengl shading language as described above sample applications several sample applications are bundled with the framework source most are compatible with both iphone and ipad class devices they attempt to show off various aspects of the framework and should be used as the best examples of the api while the framework is under development these include simpleimagefilter a bundled jpeg image is loaded into the application at launch a filter is applied to it and the result rendered to the screen additionally this sample shows two ways of taking in an image filtering it and saving it to disk simplevideofilter a pixellate filter is applied to a live video stream with a uislider control that lets you adjust the pixel size on the live video simplevideofilefilter a movie file is loaded from disk an unsharp mask filter is applied to it and the filtered result is re encoded as another movie multiviewfilterexample from a single camera feed four views are populated with realtime filters applied to camera one is just the straight camera video one is a preprogrammed sepia tone and two are custom filters based on shader programs filtershowcase this demonstrates every filter supplied with gpuimage benchmarksuite this is used to test the performance of the overall framework by testing it against cpu bound routines and core image benchmarks involving still images and video are run against all three with results displayed in application cubeexample this demonstrates the ability of gpuimage to interact with opengl es rendering frames are captured from the camera a sepia filter applied to them and then they are fed into a texture to be applied to the face of a cube you can rotate with your finger this cube in turn is rendered to a texture backed framebuffer object and that texture is fed back into gpuimage to have a pixellation filter applied to it before rendering to screen in other words the path of this application is camera sepia tone filter cube pixellation filter display colorobjecttracking a version of my colortracking example from http www sunsetlakesoftware com 2010 10 22 gpu accelerated video processing mac and ios ported across to use gpuimage this application uses color in a scene to track objects from a live camera feed the four views you can switch between include the raw camera feed the camera feed with pixels matching the color threshold in white the processed video where positions are encoded as colors within the pixels passing the threshold test and finally the live video feed with a dot that tracks the selected color tapping the screen changes the color to track to match the color of the pixels under your finger tapping and dragging on the screen makes the color threshold more or less forgiving this is most obvious on the second color thresholding view currently all processing for the color averaging in the last step is done on the cpu so this is part is extremely slow